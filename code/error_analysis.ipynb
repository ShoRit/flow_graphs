{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/rdutt/anaconda3/envs/amr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_md\")\n",
    "\n",
    "japflow_data = json.load(open(\"../data/japflow/all.json\"))\n",
    "risec_data = json.load(open(\"../data/risec/train.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: 142kB [00:00, 44.4MB/s]                    \n",
      "2022-04-20 22:52:08 INFO: Downloading default packages for language: en (English)...\n",
      "2022-04-20 22:52:09 INFO: File exists: /usr0/home/rdutt/stanza_resources/en/default.zip.\n",
      "2022-04-20 22:52:20 INFO: Finished downloading models and saved to /usr0/home/rdutt/stanza_resources.\n",
      "2022-04-20 22:52:20 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-04-20 22:52:20 INFO: Use device: gpu\n",
      "2022-04-20 22:52:20 INFO: Loading: tokenize\n",
      "2022-04-20 22:52:20 INFO: Loading: pos\n",
      "2022-04-20 22:52:21 INFO: Loading: lemma\n",
      "2022-04-20 22:52:21 INFO: Loading: depparse\n",
      "2022-04-20 22:52:21 INFO: Loading: sentiment\n",
      "2022-04-20 22:52:22 INFO: Loading: constituency\n",
      "2022-04-20 22:52:22 INFO: Loading: ner\n",
      "2022-04-20 22:52:23 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "import stanza\n",
    "import readability\n",
    "\n",
    "stanza.download(\"en\")\n",
    "nlp = stanza.Pipeline(\"en\")\n",
    "datasets = [\"risec\", \"japflow\", \"mscorpus\", \"chemu\", \"wsj\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDD and MHD calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:43<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:44<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:46<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [07:29<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1728/1728 [28:17<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "depscores = ddict(lambda: ddict(list))\n",
    "\n",
    "for dataset in datasets:\n",
    "    all_data = json.load(open(f\"../data/{dataset}/train.json\"))\n",
    "    bad_sents = 0\n",
    "    cnt = 0\n",
    "    for elem in tqdm(all_data):\n",
    "        try:\n",
    "            doc = nlp(elem[\"text\"])\n",
    "            for sent in doc.sentences:\n",
    "                edges = [(word.head, word.id) for word in sent.words]\n",
    "                mdd = np.mean([abs(edge[0] - edge[1]) for edge in edges])\n",
    "                graph = nx.DiGraph(edges)\n",
    "                mhd_dict = nx.single_source_shortest_path_length(graph, source=0)\n",
    "                mhd = np.mean([mhd_dict[elem] for elem in mhd_dict])\n",
    "                depscores[dataset][\"mdd\"].append(mdd)\n",
    "                depscores[dataset][\"mhd\"].append(mhd)\n",
    "        except Exception as e:\n",
    "            bad_sents += 1\n",
    "            continue\n",
    "\n",
    "    print(bad_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risec\t 2.989321886824177 2.539308897150301 2.9375 2.5294117647058822\n",
      "japflow\t 3.0878412838985545 2.593930420600451 3.090909090909091 2.5833333333333335\n",
      "mscorpus\t 3.213898032983633 3.0123737801052966 3.2880184331797233 3.0\n",
      "chemu\t 3.407179450007151 3.373050557832743 3.361111111111111 3.28\n",
      "wsj\t 3.4529037041436648 3.2748757219622435 3.44 3.235294117647059\n"
     ]
    }
   ],
   "source": [
    "for dataset in depscores:\n",
    "    print(\n",
    "        dataset + \"\\t\",\n",
    "        np.mean(depscores[dataset][\"mdd\"]),\n",
    "        np.mean(depscores[dataset][\"mhd\"]),\n",
    "        np.median(depscores[dataset][\"mdd\"]),\n",
    "        np.median(depscores[dataset][\"mhd\"]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READABILITY SCORES FOR DIFFERENT DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 23:38:20 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2022-04-20 23:38:20 INFO: Use device: gpu\n",
      "2022-04-20 23:38:20 INFO: Loading: tokenize\n",
      "2022-04-20 23:38:21 INFO: Done loading processors!\n",
      "100%|██████████| 126/126 [00:03<00:00, 36.42it/s]\n",
      "100%|██████████| 300/300 [00:10<00:00, 29.78it/s]\n",
      "100%|██████████| 150/150 [00:10<00:00, 14.84it/s]\n",
      "100%|██████████| 720/720 [00:31<00:00, 22.87it/s]\n",
      "100%|██████████| 1728/1728 [04:15<00:00,  6.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reading_scores = ddict(list)\n",
    "all_metrics = ddict(lambda: ddict(int))\n",
    "\n",
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize\")\n",
    "readability_scores = ddict(lambda: ddict(lambda: ddict(list)))\n",
    "for dataset in datasets:\n",
    "    all_data = json.load(open(f\"../data/{dataset}/train.json\"))\n",
    "    for elem in tqdm(all_data):\n",
    "        doc = nlp(elem[\"text\"])\n",
    "        text = \"\\n\".join([sent.text for sent in doc.sentences])\n",
    "        results = readability.getmeasures(text, lang=\"en\")\n",
    "        for metric in results:\n",
    "            for submetric in results[metric]:\n",
    "                readability_scores[metric][submetric][dataset].append(\n",
    "                    results[metric][submetric]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risec</th>\n",
       "      <th>japflow</th>\n",
       "      <th>mscorpus</th>\n",
       "      <th>chemu</th>\n",
       "      <th>wsj</th>\n",
       "      <th>mean-metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.312412</td>\n",
       "      <td>4.506464</td>\n",
       "      <td>8.721315</td>\n",
       "      <td>9.526143</td>\n",
       "      <td>9.957479</td>\n",
       "      <td>Kincaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.731710</td>\n",
       "      <td>5.156976</td>\n",
       "      <td>10.821319</td>\n",
       "      <td>12.549697</td>\n",
       "      <td>11.837323</td>\n",
       "      <td>ARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.891307</td>\n",
       "      <td>7.038908</td>\n",
       "      <td>10.728023</td>\n",
       "      <td>11.348932</td>\n",
       "      <td>11.091897</td>\n",
       "      <td>Coleman-Liau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.194253</td>\n",
       "      <td>84.826005</td>\n",
       "      <td>67.293234</td>\n",
       "      <td>66.185771</td>\n",
       "      <td>61.173961</td>\n",
       "      <td>FleschReadingEase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.796647</td>\n",
       "      <td>8.252785</td>\n",
       "      <td>15.306355</td>\n",
       "      <td>16.297810</td>\n",
       "      <td>14.169591</td>\n",
       "      <td>GunningFogIndex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.714582</td>\n",
       "      <td>28.151091</td>\n",
       "      <td>47.001472</td>\n",
       "      <td>49.393523</td>\n",
       "      <td>48.538075</td>\n",
       "      <td>LIX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.089760</td>\n",
       "      <td>8.237462</td>\n",
       "      <td>13.354064</td>\n",
       "      <td>13.885608</td>\n",
       "      <td>12.351991</td>\n",
       "      <td>SMOGIndex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.834182</td>\n",
       "      <td>1.887067</td>\n",
       "      <td>5.319827</td>\n",
       "      <td>5.995492</td>\n",
       "      <td>5.792123</td>\n",
       "      <td>RIX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.128375</td>\n",
       "      <td>8.582282</td>\n",
       "      <td>14.108348</td>\n",
       "      <td>15.760958</td>\n",
       "      <td>11.971627</td>\n",
       "      <td>DaleChallIndex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.157306</td>\n",
       "      <td>4.329234</td>\n",
       "      <td>4.775770</td>\n",
       "      <td>4.864820</td>\n",
       "      <td>4.827970</td>\n",
       "      <td>characters_per_word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.232999</td>\n",
       "      <td>1.293505</td>\n",
       "      <td>1.415297</td>\n",
       "      <td>1.396979</td>\n",
       "      <td>1.469149</td>\n",
       "      <td>syll_per_word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.161595</td>\n",
       "      <td>12.392572</td>\n",
       "      <td>19.514887</td>\n",
       "      <td>22.132789</td>\n",
       "      <td>21.055166</td>\n",
       "      <td>words_per_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.476190</td>\n",
       "      <td>9.286667</td>\n",
       "      <td>11.926667</td>\n",
       "      <td>6.472222</td>\n",
       "      <td>22.211806</td>\n",
       "      <td>sentences_per_paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.764865</td>\n",
       "      <td>0.689119</td>\n",
       "      <td>0.617111</td>\n",
       "      <td>0.655916</td>\n",
       "      <td>0.620621</td>\n",
       "      <td>type_token_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>393.023810</td>\n",
       "      <td>475.833333</td>\n",
       "      <td>1101.886667</td>\n",
       "      <td>658.898611</td>\n",
       "      <td>2186.226852</td>\n",
       "      <td>characters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>116.063492</td>\n",
       "      <td>141.636667</td>\n",
       "      <td>320.880000</td>\n",
       "      <td>190.986111</td>\n",
       "      <td>663.332755</td>\n",
       "      <td>syllables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>95.246032</td>\n",
       "      <td>110.700000</td>\n",
       "      <td>238.326667</td>\n",
       "      <td>135.668056</td>\n",
       "      <td>456.886574</td>\n",
       "      <td>words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>68.055556</td>\n",
       "      <td>71.276667</td>\n",
       "      <td>131.520000</td>\n",
       "      <td>82.947222</td>\n",
       "      <td>233.409144</td>\n",
       "      <td>wordtypes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.476190</td>\n",
       "      <td>9.286667</td>\n",
       "      <td>11.926667</td>\n",
       "      <td>6.472222</td>\n",
       "      <td>22.211806</td>\n",
       "      <td>sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>paragraphs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15.357143</td>\n",
       "      <td>16.926667</td>\n",
       "      <td>61.360000</td>\n",
       "      <td>36.856944</td>\n",
       "      <td>117.947338</td>\n",
       "      <td>long_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.690476</td>\n",
       "      <td>8.896667</td>\n",
       "      <td>42.273333</td>\n",
       "      <td>25.781944</td>\n",
       "      <td>62.335069</td>\n",
       "      <td>complex_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>35.420635</td>\n",
       "      <td>29.996667</td>\n",
       "      <td>147.400000</td>\n",
       "      <td>93.684722</td>\n",
       "      <td>197.152199</td>\n",
       "      <td>complex_words_dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>10.966667</td>\n",
       "      <td>6.323611</td>\n",
       "      <td>11.973958</td>\n",
       "      <td>tobeverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.134921</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>5.081597</td>\n",
       "      <td>auxverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.960317</td>\n",
       "      <td>7.006667</td>\n",
       "      <td>7.726667</td>\n",
       "      <td>3.895833</td>\n",
       "      <td>12.442130</td>\n",
       "      <td>conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.373016</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>21.237847</td>\n",
       "      <td>pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.746032</td>\n",
       "      <td>16.990000</td>\n",
       "      <td>29.026667</td>\n",
       "      <td>14.425000</td>\n",
       "      <td>57.337384</td>\n",
       "      <td>preposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>6.513333</td>\n",
       "      <td>3.588889</td>\n",
       "      <td>8.641782</td>\n",
       "      <td>nominalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>2.127315</td>\n",
       "      <td>pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.252894</td>\n",
       "      <td>interrogative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>3.780000</td>\n",
       "      <td>2.633333</td>\n",
       "      <td>3.907407</td>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.156667</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.509722</td>\n",
       "      <td>0.825810</td>\n",
       "      <td>subordination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>1.346644</td>\n",
       "      <td>conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>1.393333</td>\n",
       "      <td>0.834722</td>\n",
       "      <td>3.037037</td>\n",
       "      <td>preposition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         risec     japflow     mscorpus       chemu          wsj  \\\n",
       "0     3.312412    4.506464     8.721315    9.526143     9.957479   \n",
       "1     3.731710    5.156976    10.821319   12.549697    11.837323   \n",
       "2     5.891307    7.038908    10.728023   11.348932    11.091897   \n",
       "3    91.194253   84.826005    67.293234   66.185771    61.173961   \n",
       "4     7.796647    8.252785    15.306355   16.297810    14.169591   \n",
       "5    27.714582   28.151091    47.001472   49.393523    48.538075   \n",
       "6     8.089760    8.237462    13.354064   13.885608    12.351991   \n",
       "7     1.834182    1.887067     5.319827    5.995492     5.792123   \n",
       "8    10.128375    8.582282    14.108348   15.760958    11.971627   \n",
       "9     4.157306    4.329234     4.775770    4.864820     4.827970   \n",
       "10    1.232999    1.293505     1.415297    1.396979     1.469149   \n",
       "11   11.161595   12.392572    19.514887   22.132789    21.055166   \n",
       "12    8.476190    9.286667    11.926667    6.472222    22.211806   \n",
       "13    0.764865    0.689119     0.617111    0.655916     0.620621   \n",
       "14  393.023810  475.833333  1101.886667  658.898611  2186.226852   \n",
       "15  116.063492  141.636667   320.880000  190.986111   663.332755   \n",
       "16   95.246032  110.700000   238.326667  135.668056   456.886574   \n",
       "17   68.055556   71.276667   131.520000   82.947222   233.409144   \n",
       "18    8.476190    9.286667    11.926667    6.472222    22.211806   \n",
       "19    1.000000    1.000000     1.000000    1.000000     1.000000   \n",
       "20   15.357143   16.926667    61.360000   36.856944   117.947338   \n",
       "21    7.690476    8.896667    42.273333   25.781944    62.335069   \n",
       "22   35.420635   29.996667   147.400000   93.684722   197.152199   \n",
       "23    0.539683    0.956667    10.966667    6.323611    11.973958   \n",
       "24    0.134921    0.316667     0.106667    0.002778     5.081597   \n",
       "25    4.960317    7.006667     7.726667    3.895833    12.442130   \n",
       "26    0.373016    1.440000     1.300000    0.261111    21.237847   \n",
       "27   13.746032   16.990000    29.026667   14.425000    57.337384   \n",
       "28    0.087302    0.126667     6.513333    3.588889     8.641782   \n",
       "29    0.000000    0.120000     0.233333    0.075000     2.127315   \n",
       "30    0.000000    0.080000     0.006667    0.008333     0.252894   \n",
       "31    0.000000    0.053333     3.780000    2.633333     3.907407   \n",
       "32    0.007937    0.156667     0.813333    0.509722     0.825810   \n",
       "33    0.000000    0.000000     0.013333    0.004167     1.346644   \n",
       "34    0.015873    0.536667     1.393333    0.834722     3.037037   \n",
       "\n",
       "                mean-metric  \n",
       "0                   Kincaid  \n",
       "1                       ARI  \n",
       "2              Coleman-Liau  \n",
       "3         FleschReadingEase  \n",
       "4           GunningFogIndex  \n",
       "5                       LIX  \n",
       "6                 SMOGIndex  \n",
       "7                       RIX  \n",
       "8            DaleChallIndex  \n",
       "9       characters_per_word  \n",
       "10            syll_per_word  \n",
       "11       words_per_sentence  \n",
       "12  sentences_per_paragraph  \n",
       "13         type_token_ratio  \n",
       "14               characters  \n",
       "15                syllables  \n",
       "16                    words  \n",
       "17                wordtypes  \n",
       "18                sentences  \n",
       "19               paragraphs  \n",
       "20               long_words  \n",
       "21            complex_words  \n",
       "22         complex_words_dc  \n",
       "23                 tobeverb  \n",
       "24                  auxverb  \n",
       "25              conjunction  \n",
       "26                  pronoun  \n",
       "27              preposition  \n",
       "28           nominalization  \n",
       "29                  pronoun  \n",
       "30            interrogative  \n",
       "31                  article  \n",
       "32            subordination  \n",
       "33              conjunction  \n",
       "34              preposition  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for metric in readability_scores:\n",
    "    for submetric in readability_scores[metric]:\n",
    "        for dataset in readability_scores[metric][submetric]:\n",
    "            val = np.mean(readability_scores[metric][submetric][dataset])\n",
    "            reading_scores[dataset].append(val)\n",
    "        reading_scores[\"mean-metric\"].append(submetric)\n",
    "\n",
    "read_df = pd.DataFrame(reading_scores)\n",
    "display(read_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:00<00:00, 77798.07it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 68687.77it/s]\n",
      "100%|██████████| 150/150 [00:00<00:00, 40342.78it/s]\n",
      "100%|██████████| 720/720 [00:00<00:00, 53446.70it/s]\n",
      "100%|██████████| 1728/1728 [00:00<00:00, 19076.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset1</th>\n",
       "      <th>risec</th>\n",
       "      <th>japflow</th>\n",
       "      <th>mscorpus</th>\n",
       "      <th>chemu</th>\n",
       "      <th>wsj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>risec</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>japflow</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mscorpus</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chemu</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wsj</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset1  risec  japflow  mscorpus  chemu   wsj\n",
       "0     risec   1.00     0.66      0.23   0.19  0.56\n",
       "1   japflow   0.38     1.00      0.19   0.14  0.53\n",
       "2  mscorpus   0.07     0.09      1.00   0.21  0.32\n",
       "3     chemu   0.04     0.05      0.15   1.00  0.16\n",
       "4       wsj   0.02     0.03      0.03   0.02  1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_dict = ddict(list)\n",
    "\n",
    "for dataset in datasets:\n",
    "    all_data = json.load(open(f\"../data/{dataset}/train.json\"))\n",
    "    for elem in tqdm(all_data):\n",
    "        tokens = elem[\"text\"].lower().split()\n",
    "        vocab_dict[dataset].extend(tokens)\n",
    "\n",
    "vocab_overlap = ddict(list)\n",
    "for i, dataset1 in enumerate(datasets):\n",
    "    vocab_overlap[\"dataset1\"].append(dataset1)\n",
    "    li = len(set(vocab_dict[dataset1]))\n",
    "    for j, dataset2 in enumerate(datasets):\n",
    "        lc = len(set(vocab_dict[dataset2]) & set(vocab_dict[dataset1]))\n",
    "        vocab_overlap[dataset2].append(round(lc / li, 2))\n",
    "\n",
    "vocab_overlap = pd.DataFrame(vocab_overlap)\n",
    "display(vocab_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPEAT THE ABOVE EXPERIMENTS WHEN THE ENTITIES ARE MASKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/rdutt/anaconda3/envs/amr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-04-28 13:38:47 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2022-04-28 13:39:51 INFO: Use device: gpu\n",
      "2022-04-28 13:39:51 INFO: Loading: tokenize\n",
      "2022-04-28 13:41:35 INFO: Loading: pos\n",
      "2022-04-28 13:41:36 INFO: Loading: lemma\n",
      "2022-04-28 13:41:36 INFO: Loading: depparse\n",
      "2022-04-28 13:41:38 INFO: Done loading processors!\n",
      "100%|██████████| 150/150 [00:00<00:00, 92290.69it/s]\n",
      "100%|██████████| 126/126 [00:00<00:00, 193867.32it/s]\n",
      "100%|██████████| 720/720 [00:00<00:00, 284118.81it/s]\n",
      "100%|██████████| 300/300 [00:00<00:00, 159438.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mscorpus Counter({'Material': 3420, 'Number': 2951, 'Operation': 2593, 'Amount-Unit': 1153, 'Condition-Unit': 1112, 'Material-Descriptor': 1014, 'Property-Misc': 379, 'Condition-Misc': 376, 'Nonrecipe-Material': 341, 'Synthesis-Apparatus': 341, 'Brand': 226, 'Apparatus-Descriptor': 130, 'Property-Type': 125, 'Amount-Misc': 115, 'Meta': 99, 'Condition-Type': 99, 'Property-Unit': 97, 'Apparatus-Unit': 87, 'Reference': 86, 'Characterization-Apparatus': 84, 'Apparatus-Property-Type': 20})\n",
      "risec Counter({'FOOD': 1561, 'AC': 1487, 'TOOL': 548, 'CONDITION_CLAUSE': 237, 'DUR': 208, 'TEMPERATURE': 195, 'OTHER': 132, 'PURPOSE_CLAUSE': 76})\n",
      "chemu Counter({'OTHER_COMPOUND': 3702, 'REACTION_STEP': 3058, 'WORKUP': 2430, 'REACTION_PRODUCT': 1637, 'STARTING_MATERIAL': 1417, 'TEMPERATURE': 1203, 'REAGENT_CATALYST': 1018, 'SOLVENT': 915, 'YIELD_OTHER': 850, 'TIME': 848, 'YIELD_PERCENT': 764, 'EXAMPLE_LABEL': 714})\n",
      "japflow Counter({'Ac': 4956, 'F': 4850, 'T': 1860, 'Sf': 1033, 'St': 868, 'D': 575, 'Q': 494, 'Af': 265, 'Ac2': 173, 'At': 14})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "import networkx as nx\n",
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize,pos,lemma,depparse\")\n",
    "depscores = ddict(list)\n",
    "all_lbls = ddict(list)\n",
    "rem_lbls = {}\n",
    "train_texts = ddict(list)\n",
    "\n",
    "for dataset in [\"mscorpus\", \"risec\", \"chemu\", \"japflow\"]:\n",
    "    all_data = json.load(open(f\"../data/{dataset}/train.json\"))\n",
    "    for elem in tqdm(all_data):\n",
    "        text = elem[\"text\"]\n",
    "        anns = elem[\"anns\"]\n",
    "        all_lbls[dataset].extend([ann[\"label\"] for ann in anns])\n",
    "\n",
    "# for dataset in all_lbls:\n",
    "#     print(dataset, Counter(all_lbls[dataset]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 6274.95it/s]\n",
      "100%|██████████| 720/720 [00:00<00:00, 26916.28it/s]\n"
     ]
    }
   ],
   "source": [
    "rem_lbls = {}\n",
    "rem_lbls[\"mscorpus\"] = {\n",
    "    \"Material\": \"material\",\n",
    "    \"Nonrecipe-Material\": \"material\",\n",
    "    \"Characterization-Apparatus\": \"equipment\",\n",
    "    \"Synthesis-Apparatus\": \"equipment\",\n",
    "}\n",
    "rem_lbls[\"chemu\"] = {\n",
    "    \"OTHER_COMPOUND\": \"compound\",\n",
    "    \"SOLVENT\": \"solvent\",\n",
    "    \"STARTING_MATERIAL\": \"material\",\n",
    "    \"REACTION_PRODUCT\": \"product\",\n",
    "    \"REAGENT_CATALYST\": \"material\",\n",
    "}\n",
    "\n",
    "train_texts = ddict(list)\n",
    "\n",
    "for dataset in [\"mscorpus\", \"chemu\"]:\n",
    "    all_data = json.load(open(f\"../data/{dataset}/train.json\"))\n",
    "    for elem in tqdm(all_data):\n",
    "        text, anns = elem[\"text\"], elem[\"anns\"]\n",
    "        anns = sorted(\n",
    "            [(ann[\"start\"], ann[\"end\"], ann[\"word\"], ann[\"label\"]) for ann in anns]\n",
    "        )\n",
    "        word_pos = 0\n",
    "        for ann in anns:\n",
    "            start, end, word, label = ann\n",
    "            if label in rem_lbls[dataset]:\n",
    "                text = (\n",
    "                    text[: start + word_pos]\n",
    "                    + rem_lbls[dataset][label]\n",
    "                    + text[end + word_pos :]\n",
    "                )\n",
    "                word_pos += len(rem_lbls[dataset][label]) - (end - start)\n",
    "                # word_pos            += len('it')-(end -start)\n",
    "\n",
    "        train_texts[dataset].append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 15:14:39 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2022-04-28 15:14:39 INFO: Use device: gpu\n",
      "2022-04-28 15:14:39 INFO: Loading: tokenize\n",
      "2022-04-28 15:14:40 INFO: Loading: pos\n",
      "2022-04-28 15:14:40 INFO: Loading: lemma\n",
      "2022-04-28 15:14:40 INFO: Loading: depparse\n",
      "2022-04-28 15:14:41 INFO: Done loading processors!\n",
      "100%|██████████| 150/150 [00:41<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:24<00:00,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "depscores = ddict(lambda: ddict(list))\n",
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize,pos,lemma,depparse\")\n",
    "for dataset in [\"mscorpus\", \"chemu\"]:\n",
    "    bad_sents = 0\n",
    "    cnt = 0\n",
    "    for text in tqdm(train_texts[dataset]):\n",
    "        # print(text)\n",
    "        doc = nlp(text)\n",
    "        for sent in doc.sentences:\n",
    "            try:\n",
    "                # print(sent)\n",
    "                edges = [(word.head, word.id) for word in sent.words]\n",
    "                # print(edges)\n",
    "                mdd = np.mean([abs(edge[0] - edge[1]) for edge in edges])\n",
    "                graph = nx.DiGraph(edges)\n",
    "                mhd_dict = nx.single_source_shortest_path_length(graph, source=0)\n",
    "                mhd = np.mean([mhd_dict[elem] for elem in mhd_dict])\n",
    "                depscores[dataset][\"mdd\"].append(mdd)\n",
    "                depscores[dataset][\"mhd\"].append(mhd)\n",
    "\n",
    "            except Exception as e:\n",
    "                # break\n",
    "                print(e)\n",
    "                bad_sents += 1\n",
    "    print(bad_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mscorpus\t 3.1631677016744675 2.9538418695525555 3.25 2.9864864864864864\n",
      "chemu\t 3.233988871986604 3.202660384093901 3.2222222222222223 3.125\n"
     ]
    }
   ],
   "source": [
    "for dataset in depscores:\n",
    "    print(\n",
    "        dataset + \"\\t\",\n",
    "        np.mean(depscores[dataset][\"mdd\"]),\n",
    "        np.mean(depscores[dataset][\"mhd\"]),\n",
    "        np.median(depscores[dataset][\"mdd\"]),\n",
    "        np.median(depscores[dataset][\"mhd\"]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 14:45:59 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2022-04-28 14:45:59 INFO: Use device: gpu\n",
      "2022-04-28 14:45:59 INFO: Loading: tokenize\n",
      "2022-04-28 14:45:59 INFO: Done loading processors!\n",
      "100%|██████████| 150/150 [00:08<00:00, 18.44it/s]\n",
      "100%|██████████| 720/720 [00:20<00:00, 34.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mscorpus</th>\n",
       "      <th>chemu</th>\n",
       "      <th>mean-metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.479796</td>\n",
       "      <td>4.456937</td>\n",
       "      <td>Kincaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.099126</td>\n",
       "      <td>5.579919</td>\n",
       "      <td>ARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.703807</td>\n",
       "      <td>4.630015</td>\n",
       "      <td>Coleman-Liau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.953534</td>\n",
       "      <td>96.104106</td>\n",
       "      <td>FleschReadingEase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.768545</td>\n",
       "      <td>11.812992</td>\n",
       "      <td>GunningFogIndex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41.082362</td>\n",
       "      <td>37.528929</td>\n",
       "      <td>LIX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.266808</td>\n",
       "      <td>10.604554</td>\n",
       "      <td>SMOGIndex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.160008</td>\n",
       "      <td>3.466634</td>\n",
       "      <td>RIX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.209286</td>\n",
       "      <td>13.264464</td>\n",
       "      <td>DaleChallIndex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.271761</td>\n",
       "      <td>3.767997</td>\n",
       "      <td>characters_per_word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.333108</td>\n",
       "      <td>1.086616</td>\n",
       "      <td>syll_per_word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.818264</td>\n",
       "      <td>18.525303</td>\n",
       "      <td>words_per_sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.740000</td>\n",
       "      <td>6.495833</td>\n",
       "      <td>sentences_per_paragraph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.546800</td>\n",
       "      <td>0.602266</td>\n",
       "      <td>type_token_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>937.073333</td>\n",
       "      <td>441.330556</td>\n",
       "      <td>characters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>286.946667</td>\n",
       "      <td>128.576389</td>\n",
       "      <td>syllables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>227.500000</td>\n",
       "      <td>115.898611</td>\n",
       "      <td>words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>111.320000</td>\n",
       "      <td>63.938889</td>\n",
       "      <td>wordtypes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.740000</td>\n",
       "      <td>6.495833</td>\n",
       "      <td>sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>paragraphs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>46.886667</td>\n",
       "      <td>22.284722</td>\n",
       "      <td>long_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32.986667</td>\n",
       "      <td>13.420833</td>\n",
       "      <td>complex_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>113.560000</td>\n",
       "      <td>63.165278</td>\n",
       "      <td>complex_words_dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.966667</td>\n",
       "      <td>6.363889</td>\n",
       "      <td>tobeverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>auxverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.713333</td>\n",
       "      <td>3.902778</td>\n",
       "      <td>conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28.913333</td>\n",
       "      <td>12.212500</td>\n",
       "      <td>pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.993333</td>\n",
       "      <td>14.406944</td>\n",
       "      <td>preposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.260000</td>\n",
       "      <td>3.594444</td>\n",
       "      <td>nominalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.593333</td>\n",
       "      <td>0.873611</td>\n",
       "      <td>pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>interrogative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.773333</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.515278</td>\n",
       "      <td>subordination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.413333</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>preposition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mscorpus       chemu              mean-metric\n",
       "0     7.479796    4.456937                  Kincaid\n",
       "1     8.099126    5.579919                      ARI\n",
       "2     7.703807    4.630015             Coleman-Liau\n",
       "3    74.953534   96.104106        FleschReadingEase\n",
       "4    13.768545   11.812992          GunningFogIndex\n",
       "5    41.082362   37.528929                      LIX\n",
       "6    12.266808   10.604554                SMOGIndex\n",
       "7     4.160008    3.466634                      RIX\n",
       "8    12.209286   13.264464           DaleChallIndex\n",
       "9     4.271761    3.767997      characters_per_word\n",
       "10    1.333108    1.086616            syll_per_word\n",
       "11   18.818264   18.525303       words_per_sentence\n",
       "12   11.740000    6.495833  sentences_per_paragraph\n",
       "13    0.546800    0.602266         type_token_ratio\n",
       "14  937.073333  441.330556               characters\n",
       "15  286.946667  128.576389                syllables\n",
       "16  227.500000  115.898611                    words\n",
       "17  111.320000   63.938889                wordtypes\n",
       "18   11.740000    6.495833                sentences\n",
       "19    1.000000    1.000000               paragraphs\n",
       "20   46.886667   22.284722               long_words\n",
       "21   32.986667   13.420833            complex_words\n",
       "22  113.560000   63.165278         complex_words_dc\n",
       "23   10.966667    6.363889                 tobeverb\n",
       "24    0.106667    0.002778                  auxverb\n",
       "25    7.713333    3.902778              conjunction\n",
       "26   28.913333   12.212500                  pronoun\n",
       "27   28.993333   14.406944              preposition\n",
       "28    5.260000    3.594444           nominalization\n",
       "29    1.593333    0.873611                  pronoun\n",
       "30    0.006667    0.008333            interrogative\n",
       "31    3.773333    2.650000                  article\n",
       "32    0.826667    0.515278            subordination\n",
       "33    0.013333    0.004167              conjunction\n",
       "34    1.413333    0.844444              preposition"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import readability\n",
    "\n",
    "reading_scores = ddict(list)\n",
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize\")\n",
    "mod_readability_scores = ddict(lambda: ddict(lambda: ddict(list)))\n",
    "for dataset in [\"mscorpus\", \"chemu\"]:\n",
    "    for text in tqdm(train_texts[dataset]):\n",
    "        doc = nlp(text)\n",
    "        text = \"\\n\".join([sent.text for sent in doc.sentences])\n",
    "        results = readability.getmeasures(text, lang=\"en\")\n",
    "        for metric in results:\n",
    "            for submetric in results[metric]:\n",
    "                mod_readability_scores[metric][submetric][dataset].append(\n",
    "                    results[metric][submetric]\n",
    "                )\n",
    "\n",
    "for metric in mod_readability_scores:\n",
    "    for submetric in mod_readability_scores[metric]:\n",
    "        for dataset in mod_readability_scores[metric][submetric]:\n",
    "            val = np.mean(mod_readability_scores[metric][submetric][dataset])\n",
    "            reading_scores[dataset].append(val)\n",
    "        reading_scores[\"mean-metric\"].append(submetric)\n",
    "\n",
    "read_df = pd.DataFrame(reading_scores)\n",
    "display(read_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Overlap Mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5647977941176471 0.822380106571936\n"
     ]
    }
   ],
   "source": [
    "risec_vocab, japflow_vocab, risec_ent_vocab, japflow_ent_vocab = (\n",
    "    ddict(int),\n",
    "    ddict(int),\n",
    "    ddict(int),\n",
    "    ddict(int),\n",
    ")\n",
    "\n",
    "for elem in japflow_data:\n",
    "    words = [x.text.lower() for x in nlp(elem[\"text\"])]\n",
    "    for word in words:\n",
    "        japflow_vocab[word] += 1\n",
    "\n",
    "for elem in risec_data:\n",
    "    words = [x.text.lower() for x in nlp(elem[\"text\"])]\n",
    "    for word in words:\n",
    "        risec_vocab[word] += 1\n",
    "\n",
    "for elem in japflow_data:\n",
    "    anns = elem[\"anns\"]\n",
    "    for ann in anns:\n",
    "        japflow_ent_vocab[ann[\"word\"].lower()] += 1\n",
    "\n",
    "for elem in risec_data:\n",
    "    anns = elem[\"anns\"]\n",
    "    for ann in anns:\n",
    "        risec_ent_vocab[ann[\"word\"].lower()] += 1\n",
    "\n",
    "risec_vocab_set = set(risec_vocab.keys())\n",
    "japflow_vocab_set = set(japflow_vocab.keys())\n",
    "risec_ent_set = set(risec_ent_vocab.keys())\n",
    "japflow_ent_set = set(japflow_ent_vocab.keys())\n",
    "\n",
    "oov_japflow = len(japflow_vocab_set - risec_vocab_set) / len(japflow_vocab_set)\n",
    "oov_japflow_ent = len(japflow_ent_set - risec_ent_set) / len(japflow_ent_set)\n",
    "\n",
    "print(oov_japflow, oov_japflow_ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "risec_sent_dict, japflow_sent_dict = ddict(int), ddict(int)\n",
    "tot_risec_sents, tot_japflow_sents = 0, 0\n",
    "for elem in risec_data:\n",
    "    sents = [x for x in nlp(elem[\"text\"]).sents]\n",
    "    for sent in sents:\n",
    "        risec_sent_dict[min(len(sent), 40)] += 1\n",
    "        tot_risec_sents += 1\n",
    "\n",
    "for elem in japflow_data:\n",
    "    sents = [x for x in nlp(elem[\"text\"]).sents]\n",
    "    for sent in sents:\n",
    "        japflow_sent_dict[min(len(sent), 40)] += 1\n",
    "        tot_japflow_sents += 1\n",
    "\n",
    "sent_dict = ddict(list)\n",
    "for elem in risec_sent_dict:\n",
    "    sent_dict[\"length\"].append(elem)\n",
    "    sent_dict[\"prop\"].append(risec_sent_dict[elem] / tot_risec_sents)\n",
    "    sent_dict[\"data\"].append(\"risec\")\n",
    "\n",
    "for elem in japflow_sent_dict:\n",
    "    sent_dict[\"length\"].append(elem)\n",
    "    sent_dict[\"prop\"].append(japflow_sent_dict[elem] / tot_japflow_sents)\n",
    "    sent_dict[\"data\"].append(\"japflow\")\n",
    "\n",
    "sent_df = pd.DataFrame(sent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=sent_df, x=\"length\", y=\"prop\", hue=\"data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of the dependency links between entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "risec_rels = load_dill(f\"../data/risec/data.dill\")[\"train\"][\"rels\"]\n",
    "japflow_rels = load_dill(f\"../data/japflow/data.dill\")[\"all\"][\"rels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3689/3689 [00:35<00:00, 103.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "risec_min_path_dict = ddict(int)\n",
    "\n",
    "for rel in tqdm(risec_rels):\n",
    "    org_toks, toks_range = rel[\"org_toks\"], rel[\"tok_range\"]\n",
    "    sent = org_toks[0]\n",
    "    for i in range(1, len(org_toks)):\n",
    "        diff = toks_range[i][0] - toks_range[i - 1][1]\n",
    "        for j in range(diff):\n",
    "            sent += \" \"\n",
    "        sent += org_toks[i]\n",
    "    obj1_start, obj1_end, obj1_text = (\n",
    "        rel[\"span_info\"][0],\n",
    "        rel[\"span_info\"][1],\n",
    "        rel[\"span_info\"][2],\n",
    "    )\n",
    "    obj2_start, obj2_end, obj2_text = (\n",
    "        rel[\"span_info\"][4],\n",
    "        rel[\"span_info\"][5],\n",
    "        rel[\"span_info\"][6],\n",
    "    )\n",
    "\n",
    "    doc = nlp(sent)\n",
    "    src_ents, tgt_ents, edges = [], [], []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"DET\", \"CONJ\", \"SYM\"]:\n",
    "            continue\n",
    "        if token.text in obj1_text:\n",
    "            src_ents.append(token.text)\n",
    "        if token.text in obj2_text:\n",
    "            tgt_ents.append(token.text)\n",
    "        for child in token.children:\n",
    "            edges.append((\"{0}\".format(token.text), \"{0}\".format(child.text)))\n",
    "\n",
    "    graph = nx.Graph(edges)\n",
    "    min_path = len(org_toks)\n",
    "\n",
    "    for src in src_ents:\n",
    "        for tgt in tgt_ents:\n",
    "            try:\n",
    "                min_path = min(\n",
    "                    min_path, nx.shortest_path_length(graph, source=src, target=tgt)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    risec_min_path_dict[min_path] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15861/15861 [02:51<00:00, 92.28it/s] \n"
     ]
    }
   ],
   "source": [
    "japflow_min_path_dict = ddict(int)\n",
    "\n",
    "for rel in tqdm(japflow_rels):\n",
    "    org_toks, toks_range = rel[\"org_toks\"], rel[\"tok_range\"]\n",
    "    sent = org_toks[0]\n",
    "    for i in range(1, len(org_toks)):\n",
    "        diff = toks_range[i][0] - toks_range[i - 1][1]\n",
    "        for j in range(diff):\n",
    "            sent += \" \"\n",
    "        sent += org_toks[i]\n",
    "    obj1_start, obj1_end, obj1_text = (\n",
    "        rel[\"span_info\"][0],\n",
    "        rel[\"span_info\"][1],\n",
    "        rel[\"span_info\"][2],\n",
    "    )\n",
    "    obj2_start, obj2_end, obj2_text = (\n",
    "        rel[\"span_info\"][4],\n",
    "        rel[\"span_info\"][5],\n",
    "        rel[\"span_info\"][6],\n",
    "    )\n",
    "\n",
    "    doc = nlp(sent)\n",
    "    src_ents, tgt_ents, edges = [], [], []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"DET\", \"CONJ\", \"SYM\"]:\n",
    "            continue\n",
    "        if token.text in obj1_text:\n",
    "            src_ents.append(token.text)\n",
    "        if token.text in obj2_text:\n",
    "            tgt_ents.append(token.text)\n",
    "        for child in token.children:\n",
    "            edges.append((\"{0}\".format(token.text), \"{0}\".format(child.text)))\n",
    "\n",
    "    graph = nx.Graph(edges)\n",
    "\n",
    "    min_path = len(org_toks)\n",
    "\n",
    "    for src in src_ents:\n",
    "        for tgt in tgt_ents:\n",
    "            try:\n",
    "                min_path = min(\n",
    "                    min_path, nx.shortest_path_length(graph, source=src, target=tgt)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    japflow_min_path_dict[min_path] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "risec_deps = np.sum([risec_min_path_dict[elem] for elem in risec_min_path_dict])\n",
    "japflow_deps = np.sum([japflow_min_path_dict[elem] for elem in japflow_min_path_dict])\n",
    "\n",
    "dep_dict = ddict(list)\n",
    "\n",
    "for path in risec_min_path_dict:\n",
    "    dep_dict[\"length\"].append(min(path, 7))\n",
    "    dep_dict[\"prop\"].append(risec_min_path_dict[path] / risec_deps)\n",
    "    dep_dict[\"data\"].append(\"risec\")\n",
    "\n",
    "for path in japflow_min_path_dict:\n",
    "    dep_dict[\"length\"].append(min(path, 7))\n",
    "    dep_dict[\"prop\"].append(japflow_min_path_dict[path] / japflow_deps)\n",
    "    dep_dict[\"data\"].append(\"japflow\")\n",
    "\n",
    "dep_df = pd.DataFrame(dep_dict)\n",
    "\n",
    "sns.lineplot(data=dep_df, x=\"length\", y=\"prop\", hue=\"data\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3689/3689 [00:00<00:00, 788422.29it/s]\n",
      "100%|██████████| 15861/15861 [00:00<00:00, 364785.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12) When inserted it should come out clean. (589, 593, 'come', 'AC', 579, 581, 'it', 'TOOL', 'Arg_PAG')\n",
      "4) Let them warm up for about 90 seconds. (183, 190, 'warm up', 'AC', 178, 182, 'them', 'FOOD', 'Arg_PAG')\n",
      "8) Let them cool for 2 minutes before removing from cookie sheets to cool completely. (451, 455, 'cool', 'AC', 446, 450, 'them', 'FOOD', 'Arg_PAG')\n",
      "9) Beat on low speed for 2 minutes. 10) Let stand for 2-3 minutes. (452, 457, 'stand', 'AC', 411, 415, 'Beat', 'AC', 'Arg_PAG')\n",
      "3) Remove from the heat and let stand at room temperature until cold, several hours. (158, 163, 'stand', 'AC', 129, 135, 'Remove', 'AC', 'Arg_PAG')\n",
      "7) Overbeaten egg whites lose volume and deflate when folded into other ingredients. (350, 354, 'lose', 'AC', 328, 349, 'Overbeaten egg whites', 'FOOD', 'Arg_PAG')\n",
      "7) Overbeaten egg whites lose volume and deflate when folded into other ingredients. (366, 373, 'deflate', 'AC', 328, 349, 'Overbeaten egg whites', 'FOOD', 'Arg_PAG')\n",
      "8) Be absolutely sure not a particle of grease or egg yolk gets into the whites. (469, 473, 'gets', 'AC', 432, 468, 'not a particle of grease or egg yolk', 'FOOD', 'Arg_PAG')\n",
      "3) Let the almonds soak in water for about 5 minutes, then drain and peel. (97, 101, 'soak', 'AC', 85, 96, 'the almonds', 'FOOD', 'Arg_PAG')\n",
      "8) Add 1 teaspoon lemon juice, reduce heat to low, and let it simmer until syrupy, about 30 to 40 minutes. (550, 556, 'simmer', 'AC', 547, 549, 'it', 'FOOD', 'Arg_PAG')\n",
      "\n",
      "\n",
      "****************************\n",
      "\n",
      "\n",
      "Let the yeast dissolve and foam for 10 minutes. (74, 79, 'yeast', 'F', 80, 88, 'dissolve', 'Af', 'agent')\n",
      "Let cool for 10 minutes. (336, 339, 'Let', 'Ac', 340, 344, 'cool', 'Af', 'agent')\n",
      "Let cool slightly, then stir in the vinegar and sugar. (424, 427, 'Let', 'Ac', 428, 432, 'cool', 'Af', 'agent')\n",
      "Let stand 10 minutes. (196, 199, 'Let', 'Ac', 200, 205, 'stand', 'Af', 'agent')\n",
      "Let the lasagne rest for ten minutes before serving. (1139, 1146, 'lasagne', 'F', 1147, 1151, 'rest', 'Af', 'agent')\n",
      "Let it stand until cabbage wilts, at least 1 hour and up to 4 hours. (84, 87, 'Let', 'Ac', 91, 96, 'stand', 'Af', 'agent')\n",
      "Let it stand until cabbage wilts, at least 1 hour and up to 4 hours. (103, 110, 'cabbage', 'F', 111, 116, 'wilts', 'Af', 'agent')\n",
      "Let cool, then squeeze the paper and drain excess water from the tofu very well. (81, 84, 'Let', 'Ac', 85, 89, 'cool', 'Af', 'agent')\n",
      "Let the chicken marinate at least 2 hours ; overnight is best. (158, 161, 'Let', 'Ac', 174, 182, 'marinate', 'Af', 'agent')\n",
      "Let stand 5 to 6 minutes, until mixture is foamy. (51, 54, 'Let', 'Ac', 55, 60, 'stand', 'Af', 'agent')\n",
      "Let stand 5 to 6 minutes, until mixture is foamy. In a large bowl, mix together 1/2 of the remaining flour, remaining water, salt, oregano and butter. (83, 90, 'mixture', 'F', 94, 99, 'foamy', 'Sf', 'agent')\n",
      "Let stand at room temperature for 15 minutes, stirring occasionally. (131, 134, 'Let', 'Ac', 135, 140, 'stand', 'Af', 'agent')\n",
      "Let stand for another 30 minutes at room temperature. (236, 239, 'Let', 'Ac', 240, 245, 'stand', 'Af', 'agent')\n",
      "Let rest for fives minutes, then allow to cool fully on a wire rack. (424, 427, 'Let', 'Ac', 428, 432, 'rest', 'Af', 'agent')\n",
      "Let rest for fives minutes, then allow to cool fully on a wire rack. (457, 462, 'allow', 'Ac', 466, 470, 'cool', 'Af', 'agent')\n",
      "Let cool in pan for 10 minutes, then turn out onto a wire rack and cool completely. (422, 425, 'Let', 'Ac', 426, 430, 'cool', 'Af', 'agent')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for rel in tqdm(risec_rels):\n",
    "    if rel[\"span_info\"][-1] != \"Arg_PAG\":\n",
    "        continue\n",
    "    org_toks, toks_range = rel[\"org_toks\"], rel[\"tok_range\"]\n",
    "    sent = org_toks[0]\n",
    "    for i in range(1, len(org_toks)):\n",
    "        diff = toks_range[i][0] - toks_range[i - 1][1]\n",
    "        for j in range(diff):\n",
    "            sent += \" \"\n",
    "        sent += org_toks[i]\n",
    "    obj1_start, obj1_end, obj1_text = (\n",
    "        rel[\"span_info\"][0],\n",
    "        rel[\"span_info\"][1],\n",
    "        rel[\"span_info\"][2],\n",
    "    )\n",
    "    obj2_start, obj2_end, obj2_text = (\n",
    "        rel[\"span_info\"][4],\n",
    "        rel[\"span_info\"][5],\n",
    "        rel[\"span_info\"][6],\n",
    "    )\n",
    "    print(sent, rel[\"span_info\"])\n",
    "\n",
    "print(\"\\n\\n****************************\\n\\n\")\n",
    "for rel in tqdm(japflow_rels):\n",
    "    if rel[\"span_info\"][-1] != \"agent\":\n",
    "        continue\n",
    "    org_toks, toks_range = rel[\"org_toks\"], rel[\"tok_range\"]\n",
    "    sent = org_toks[0]\n",
    "    for i in range(1, len(org_toks)):\n",
    "        diff = toks_range[i][0] - toks_range[i - 1][1]\n",
    "        for j in range(diff):\n",
    "            sent += \" \"\n",
    "        sent += org_toks[i]\n",
    "    obj1_start, obj1_end, obj1_text = (\n",
    "        rel[\"span_info\"][0],\n",
    "        rel[\"span_info\"][1],\n",
    "        rel[\"span_info\"][2],\n",
    "    )\n",
    "    obj2_start, obj2_end, obj2_text = (\n",
    "        rel[\"span_info\"][4],\n",
    "        rel[\"span_info\"][5],\n",
    "        rel[\"span_info\"][6],\n",
    "    )\n",
    "    if sent.startswith(\"Let\"):\n",
    "        print(sent, rel[\"span_info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rel in tqdm(risec_rels):\n",
    "    if rel[\"span_info\"][-1] != \"Arg_\":\n",
    "        continue\n",
    "    org_toks, toks_range = rel[\"org_toks\"], rel[\"tok_range\"]\n",
    "    sent = org_toks[0]\n",
    "    for i in range(1, len(org_toks)):\n",
    "        diff = toks_range[i][0] - toks_range[i - 1][1]\n",
    "        for j in range(diff):\n",
    "            sent += \" \"\n",
    "        sent += org_toks[i]\n",
    "    obj1_start, obj1_end, obj1_text = (\n",
    "        rel[\"span_info\"][0],\n",
    "        rel[\"span_info\"][1],\n",
    "        rel[\"span_info\"][2],\n",
    "    )\n",
    "    obj2_start, obj2_end, obj2_text = (\n",
    "        rel[\"span_info\"][4],\n",
    "        rel[\"span_info\"][5],\n",
    "        rel[\"span_info\"][6],\n",
    "    )\n",
    "    print(sent, rel[\"span_info\"])\n",
    "\n",
    "print(\"\\n\\n****************************\\n\\n\")\n",
    "for rel in tqdm(japflow_rels):\n",
    "    if rel[\"span_info\"][-1] != \"dest\":\n",
    "        continue\n",
    "    org_toks, toks_range = rel[\"org_toks\"], rel[\"tok_range\"]\n",
    "    sent = org_toks[0]\n",
    "    for i in range(1, len(org_toks)):\n",
    "        diff = toks_range[i][0] - toks_range[i - 1][1]\n",
    "        for j in range(diff):\n",
    "            sent += \" \"\n",
    "        sent += org_toks[i]\n",
    "    obj1_start, obj1_end, obj1_text = (\n",
    "        rel[\"span_info\"][0],\n",
    "        rel[\"span_info\"][1],\n",
    "        rel[\"span_info\"][2],\n",
    "    )\n",
    "    obj2_start, obj2_end, obj2_text = (\n",
    "        rel[\"span_info\"][4],\n",
    "        rel[\"span_info\"][5],\n",
    "        rel[\"span_info\"][6],\n",
    "    )\n",
    "    if sent.startswith(\"Let\"):\n",
    "        print(sent, rel[\"span_info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_srl import dataset_readers, models, predictors\n",
    "\n",
    "predictor = predictors.SrlTransformersPredictor.from_path(\n",
    "    \"/projects/flow_graphs/models/srl_bert_base_conll2012.tar.gz\", \"transformer_srl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verb': 'combine', 'description': '[ARGM-LOC: in a large saucepan] , [combine.01: combine] [ARG1: chocolate chips and 1 cup heavy cream . 20 ) heat] , [ARGM-PRD: stirring constantly , until chocolate is melted and smooth] .', 'tags': ['B-ARGM-LOC', 'I-ARGM-LOC', 'I-ARGM-LOC', 'I-ARGM-LOC', 'O', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'O', 'B-ARGM-PRD', 'I-ARGM-PRD', 'I-ARGM-PRD', 'I-ARGM-PRD', 'I-ARGM-PRD', 'I-ARGM-PRD', 'I-ARGM-PRD', 'I-ARGM-PRD', 'I-ARGM-PRD', 'O'], 'frame': 'combine.01', 'frame_score': 0.9999986886978149, 'lemma': 'combine'}\n",
      "{'verb': 'stirring', 'description': 'in a large saucepan , combine chocolate chips and 1 cup heavy cream . 20 ) heat , [stir.01: stirring] [ARGM-TMP: constantly] , [ARGM-TMP: until chocolate is melted and smooth] .', 'tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-V', 'B-ARGM-TMP', 'O', 'B-ARGM-TMP', 'I-ARGM-TMP', 'I-ARGM-TMP', 'I-ARGM-TMP', 'I-ARGM-TMP', 'I-ARGM-TMP', 'O'], 'frame': 'stir.01', 'frame_score': 0.9975645542144775, 'lemma': 'stir'}\n",
      "{'verb': 'is', 'description': 'in a large saucepan , combine chocolate chips and 1 cup heavy cream . 20 ) heat , stirring constantly , until [ARG1: chocolate] [be.01: is] [ARG2: melted and smooth] .', 'tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ARG1', 'B-V', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'O'], 'frame': 'be.01', 'frame_score': 0.9999983310699463, 'lemma': 'be'}\n",
      "{'verb': 'melted', 'description': 'in a large saucepan , combine chocolate chips and 1 cup heavy cream . 20 ) heat , stirring constantly , until [ARG1: chocolate] is [melt.01: melted] and smooth .', 'tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ARG1', 'O', 'B-V', 'O', 'O', 'O'], 'frame': 'melt.01', 'frame_score': 0.9998700618743896, 'lemma': 'melt'}\n"
     ]
    }
   ],
   "source": [
    "sent = \"\"\"\n",
    "In a large saucepan, combine chocolate chips and 1 cup heavy cream.\n",
    "20) Heat, stirring constantly, until chocolate is melted and smooth.\n",
    "\"\"\".lower()\n",
    "srls = predictor.predict(sentence=sent)\n",
    "for frame in srls[\"verbs\"]:\n",
    "    print(frame)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a large saucepan, combine chocolate chips and 1 cup heavy cream.\n",
      "20) Heat, stirring constantly, until chocolate is melted and smooth.\n",
      "\n",
      "{'nodes': {0: ['combine'], 1: ['In', 'a', 'large', 'saucepan'], 2: ['melted'], 3: ['chocolate'], 4: ['stirring'], 5: [], 6: ['is', 'melted'], 7: ['combine', 'chocolate', 'chips', 'and', '1', 'cup', 'heavy', 'cream', '.', '20', ')', 'Heat', ',', 'stirring', 'constantly', ',', 'until', 'chocolate', 'is']}, 'edge_index': [[0, 2, 4, 4, 4, 4, 7, 6, 6], [1, 3, 5, 5, 5, 6, 5, 5, 5]], 'edge_type': ['ARGM-LOC', 'ARG1', 'ARG1', 'ARGM-TMP', 'ARGM-TMP', 'ARGM-TMP', 'ARG1', 'ARG1', 'ARG2']}\n",
      "\n",
      "1) Cream together butter, peanut butter and sugars.\n",
      "2) Beat in eggs.\n",
      "\n",
      "{'nodes': {0: ['Beat'], 1: ['eggs']}, 'edge_index': [[0], [1]], 'edge_type': ['ARG1']}\n",
      "\n",
      "8) Bake in a preheated oven for 8 to 10 minutes or until golden brown.\n",
      "\n",
      "{'nodes': {}, 'edge_index': [[], []], 'edge_type': []}\n",
      "\n",
      "4) Measure 1/2 cup of the mixture into re-sealable bags or containers for storage.\n",
      "5) Label and date each bag.\n",
      "\n",
      "{'nodes': {}, 'edge_index': [[], []], 'edge_type': []}\n",
      "\n",
      "3) Place the onion in the skillet, and cook until tender.\n",
      "4) Mix in the garlic, ginger paste, green chile peppers, and tomatoes.\n",
      "\n",
      "{'nodes': {0: ['Mix'], 1: ['in'], 2: ['the', 'garlic', ',', 'ginger', 'paste', ',', 'green', 'chile', 'peppers', ',', 'and', 'tomatoes'], 3: ['Place', 'the', 'onion', 'in', 'the', 'skillet', ',', 'and', 'cook'], 4: [], 5: ['cook', 'until', 'tender', '.', '4', ')', 'Mix']}, 'edge_index': [[0, 0, 3, 3, 5], [1, 2, 4, 4, 4]], 'edge_type': ['ARG2', 'ARG1', 'ARG1', 'ARG2', 'ARGM-TMP']}\n",
      "\n",
      "3) Place hot dogs into a slow cooker on low heat.\n",
      "\n",
      "{'nodes': {0: ['Place'], 1: ['hot', 'dogs'], 2: ['into', 'a', 'slow', 'cooker', 'on', 'low', 'heat']}, 'edge_index': [[0, 0], [1, 2]], 'edge_type': ['ARG1', 'ARG2']}\n",
      "\n",
      "9) Pour batter into prepared pan.\n",
      "\n",
      "{'nodes': {0: ['Pour'], 1: ['batter'], 2: ['into', 'prepared', 'pan']}, 'edge_index': [[0, 0], [1, 2]], 'edge_type': ['ARG1', 'ARG2']}\n",
      "\n",
      "1) Wash chicken breasts in water and then place in a pot with water just to cover the chicken.\n",
      "2) Add some salt and pepper and garlic powder.\n",
      "\n",
      "{'nodes': {0: ['place'], 1: ['then'], 2: ['in', 'a', 'pot', 'with', 'water'], 3: ['cover'], 4: ['just'], 5: ['the', 'chicken'], 6: ['Add'], 7: ['some', 'salt', 'and', 'pepper', 'and', 'garlic', 'powder'], 8: [], 9: ['Wash', 'chicken', 'breasts', 'in', 'water', 'and', 'then', 'place']}, 'edge_index': [[0, 0, 3, 3, 6, 8, 9, 9], [1, 2, 4, 5, 7, 3, 8, 8]], 'edge_type': ['ARGM-TMP', 'ARG2', 'ARGM-ADV', 'ARG1', 'ARG1', 'ARGM-PRP', 'ARG1', 'ARG2']}\n",
      "\n",
      "13) Remove bread from pan to rack to cool.\n",
      "\n",
      "{'nodes': {0: ['Remove'], 1: ['bread'], 2: ['from', 'pan', 'to', 'rack'], 3: ['to', 'cool'], 4: ['rack']}, 'edge_index': [[0, 0, 0, 4], [1, 2, 3, 3]], 'edge_type': ['ARG1', 'ARG2', 'ARGM-PRP', 'ARG1']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "\n",
    "srl_dict = load_pickle(\"../data/risec/srl_sents.pkl\")\n",
    "\n",
    "count = 0\n",
    "for sent in srl_dict:\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break\n",
    "    print(sent)\n",
    "    print(srl_dict[sent])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance for AMRLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences = 3689\n"
     ]
    }
   ],
   "source": [
    "import amrlib, spacy\n",
    "from helper import load_pickle\n",
    "from amrlib.graph_processing.annotator import add_lemmas\n",
    "import re\n",
    "from amrlib.alignments.rbw_aligner import RBWAligner\n",
    "import json\n",
    "from helper import *\n",
    "from intervals import *\n",
    "\n",
    "bad_sents = []\n",
    "graph_len = []\n",
    "amr_sents = []\n",
    "data_dir = \"../data/risec\"\n",
    "split = \"train\"\n",
    "docs = json.load(open(f\"{data_dir}/{split}.json\"))\n",
    "nlp = spacy.load(\"en_core_sci_md\")\n",
    "\n",
    "for count, doc in enumerate(docs):\n",
    "    print(f\"Done for {count}/{len(docs)}\", end=\"\\r\")\n",
    "    rel_map = {}\n",
    "    lbl_cnt = ddict(int)\n",
    "    interdict = ddict(list)\n",
    "    parses_arr = []\n",
    "\n",
    "    sents = [x for x in nlp(doc[\"text\"]).sents]\n",
    "\n",
    "    for rel in doc[\"rels\"]:\n",
    "        start_span = min(rel[\"arg1_start\"], rel[\"arg2_start\"])\n",
    "        end_span = max(rel[\"arg1_end\"], rel[\"arg2_end\"])\n",
    "        rel_map[(start_span, end_span)] = (\n",
    "            rel[\"arg1_start\"],\n",
    "            rel[\"arg1_end\"],\n",
    "            rel[\"arg1_word\"],\n",
    "            rel[\"arg1_label\"],\n",
    "            rel[\"arg2_start\"],\n",
    "            rel[\"arg2_end\"],\n",
    "            rel[\"arg2_word\"],\n",
    "            rel[\"arg2_label\"],\n",
    "            rel[\"arg_label\"],\n",
    "        )\n",
    "\n",
    "    # sent_idxs = [0]+[max([tok.idx for tok in sent])+1 for sent in sents]\n",
    "    sent_idxs = [0] + [sent.end_char for sent in sents]\n",
    "    sent_ints = [(sent_idxs[i], sent_idxs[i + 1]) for i in range(0, len(sent_idxs) - 1)]\n",
    "    rel_ints = sorted(rel_map)\n",
    "\n",
    "    for rel_start, rel_end in rel_ints:\n",
    "        for sent_cnt, sent in enumerate(sent_ints):\n",
    "            sent_start, sent_end = sent_ints[sent_cnt]\n",
    "            if rel_start > sent_end:\n",
    "                continue\n",
    "            if rel_end < sent_start:\n",
    "                break\n",
    "            interdict[(rel_start, rel_end)].append(\n",
    "                (sents[sent_cnt], sent_ints[sent_cnt][0])\n",
    "            )\n",
    "\n",
    "    for rel_int in interdict:\n",
    "        (\n",
    "            arg1_start,\n",
    "            arg1_end,\n",
    "            arg1_word,\n",
    "            arg1_label,\n",
    "            arg2_start,\n",
    "            arg2_end,\n",
    "            arg2_word,\n",
    "            arg2_label,\n",
    "            arg_lbl,\n",
    "        ) = rel_map[rel_int]\n",
    "        arg1_ann_map, arg2_ann_map, bw_arg_ann_map = (\n",
    "            IntervalMapping(),\n",
    "            IntervalMapping(),\n",
    "            IntervalMapping(),\n",
    "        )\n",
    "\n",
    "        arg1_ann_map[arg1_start:arg1_end] = (arg1_start, arg1_end, arg1_label)\n",
    "        arg2_ann_map[arg2_start:arg2_end] = (arg2_start, arg2_end, arg2_label)\n",
    "        bw_arg_ann_map[min(arg1_start, arg2_start) : max(arg2_end, arg1_end)]\n",
    "\n",
    "        sent_str, sent_start = \"\", None\n",
    "\n",
    "        for elem in interdict[rel_int]:\n",
    "            sent, sent_start_pos = elem\n",
    "            if sent_start is None:\n",
    "                sent_start = sent_start_pos\n",
    "            # sent_str \t\t\t\t\t\t+=str(sent.strip())\n",
    "            sent_str += str(sent)\n",
    "            sent_toks = sent\n",
    "\n",
    "        amr_sents.append(sent_str)\n",
    "\n",
    "print(f\"Total number of sentences = {len(amr_sents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 10/10 [00:11<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "bert_model = \"bert-base-uncased\"\n",
    "nlp = spacy.load(\"en_core_sci_md\")\n",
    "\n",
    "amrlib.setup_spacy_extension()\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model)\n",
    "model = AutoModel.from_pretrained(bert_model)\n",
    "amr_dict = ddict(dict)\n",
    "\n",
    "for sent in tqdm(list(amr_sents[:10])):\n",
    "    sent = sent.replace(\"\\n\", \"\\u00A0\")\n",
    "    doc = nlp(sent)\n",
    "\n",
    "    node_dict = {}\n",
    "    edges_arr = []\n",
    "    node2str = {}\n",
    "    node2embs = {}\n",
    "\n",
    "    for count, span in enumerate(doc.sents):\n",
    "        start_tok_idx, end_tok_idx = 1, 1\n",
    "        tok_pos = []\n",
    "        bert_toks = tokenizer(span.text, return_tensors=\"pt\")\n",
    "        bert_embs = model(**bert_toks)[\"last_hidden_state\"][0]\n",
    "        input_ids = list(np.array(bert_toks[\"input_ids\"].squeeze(dim=0).cpu()))\n",
    "\n",
    "        graph_string = span._.to_amr()\n",
    "        penman_graph = add_lemmas(graph_string[0], snt_key=\"snt\")\n",
    "        aligner = RBWAligner.from_penman_w_json(\n",
    "            penman_graph\n",
    "        )  # use this with an annotated penman graph object\n",
    "        aligned_string = aligner.get_graph_string()\n",
    "        alignments = (\n",
    "            aligned_string.split(\"::\")[4]\n",
    "            .split(\"\\n\")[0]\n",
    "            .replace(\"alignments\", \"\")\n",
    "            .strip()\n",
    "            .split()\n",
    "        )\n",
    "        tokens = ast.literal_eval(\n",
    "            aligned_string.split(\"::\")[2].split(\"\\n\")[0][len(\"tokens\") + 1 :]\n",
    "        )\n",
    "\n",
    "        for tok_idx, tok_str in enumerate(tokens):\n",
    "            curr_bert_toks = tokenizer.encode(tok_str, add_special_tokens=False)\n",
    "            end_tok_idx = start_tok_idx + len(curr_bert_toks)\n",
    "            tok_pos.append((tok_str, tok_idx, start_tok_idx, end_tok_idx))\n",
    "            start_tok_idx = end_tok_idx\n",
    "\n",
    "        triples = penman_graph.triples\n",
    "        edges = penman_graph.edges()\n",
    "\n",
    "        for n1, rel, n2 in edges:\n",
    "            n1 = f\"{count}-{n1}\"\n",
    "            n2 = f\"{count}-{n2}\"\n",
    "            if n1 not in node_dict:\n",
    "                node_dict[n1] = len(node_dict)\n",
    "            if n2 not in node_dict:\n",
    "                node_dict[n2] = len(node_dict)\n",
    "\n",
    "        for edge in edges:\n",
    "            src, rel, tgt = edge.source, edge.role, edge.target\n",
    "            edges_arr.append((f\"{count}-{src}\", rel, f\"{count}-{tgt}\"))\n",
    "\n",
    "        last_aligned_str = aligned_string.split(\"::\")[4]\n",
    "        aligned_idx = last_aligned_str.index(\"\\n\") + 1\n",
    "        aligned_graph_strs = last_aligned_str[aligned_idx:].strip().split(\"\\n\")\n",
    "\n",
    "        last_node = None\n",
    "        for aligned_node in aligned_graph_strs:\n",
    "            e_match = re.search(r\"~e\\.\\d+\", aligned_node)\n",
    "            z_match = re.search(r\"\\(z\\d+ \\/\", aligned_node)\n",
    "            if e_match is not None and z_match is not None:\n",
    "                e_tok = int(e_match[0].split(\".\")[1])\n",
    "                z_node = z_match[0][1:].split(\"/\")[0]\n",
    "                node2str[f\"{count}-{z_node}\"] = tok_pos[e_tok]\n",
    "                last_node = z_node\n",
    "            elif z_match is not None:\n",
    "                z_node = z_match[0][1:].split(\"/\")[0]\n",
    "                last_node = z_node\n",
    "            elif e_match is not None:\n",
    "                e_tok = int(e_match[0].split(\".\")[1])\n",
    "                node2str[f\"{count}-{last_node}\"] = tok_pos[e_tok]\n",
    "\n",
    "        for node in node2str:\n",
    "            if not node.startswith(f\"{count}-\"):\n",
    "                continue\n",
    "            try:\n",
    "                start_idx, end_idx = node2str[node][2], node2str[node][3]\n",
    "                node2embs[node] = torch.max(bert_embs[start_idx:end_idx], dim=0)[0]\n",
    "            except:\n",
    "                node2embs[node] = torch.max(bert_embs[start_idx], dim=0)[0]\n",
    "\n",
    "    amr_dict[sent][\"node2str\"] = node2str\n",
    "    amr_dict[sent][\"node2embs\"] = node2embs\n",
    "    amr_dict[sent][\"edges_arr\"] = edges_arr\n",
    "    amr_dict[sent][\"node_dict\"] = node_dict\n",
    "    amr_dict[sent][\"triples\"] = penman_graph.triples\n",
    "    amr_dict[sent][\"tok_pos\"] = tok_pos\n",
    "    amr_dict[sent][\"aligned_graph\"] = aligned_graph_strs\n",
    "    amr_dict[sent][\"graph_str\"] = graph_string[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2) Whisk in egg yolks and cook until light custard forms; do not boil. 3) Remove from heat and cool, then place in refrigerator and chill overnight.\n",
      "('# ::snt 3) Remove from heat and cool, then place in refrigerator and chill '\n",
      " 'overnight.\\n'\n",
      " '# ::tokens [\"3\", \")\", \"Remove\", \"from\", \"heat\", \"and\", \"cool\", \",\", \"then\", '\n",
      " '\"place\", \"in\", \"refrigerator\", \"and\", \"chill\", \"overnight\", \".\"]\\n'\n",
      " '# ::lemmas [\"3\", \")\", \"remove\", \"from\", \"heat\", \"and\", \"cool\", \",\", \"then\", '\n",
      " '\"place\", \"in\", \"refrigerator\", \"and\", \"chill\", \"overnight\", \".\"]\\n'\n",
      " '# ::alignments 0-1.1 2-1.2 4-1.2.2.1 5-1 6-1.2.2.2 8-1.3.3 9-1.3.1 '\n",
      " '11-1.3.1.2 12-1.2.2 13-1.3.2 14-1.3.4\\n'\n",
      " '(z1 / and~e.5\\n'\n",
      " '      :li 3~e.0\\n'\n",
      " '      :op1 (z2 / remove-01~e.2\\n'\n",
      " '            :ARG1 (z3 / you)\\n'\n",
      " '            :ARG2 (z4 / and~e.12\\n'\n",
      " '                  :op1 (z5 / heat~e.4)\\n'\n",
      " '                  :op2 (z6 / cool~e.6)))\\n'\n",
      " '      :op2 (z7 / and\\n'\n",
      " '            :op1 (z8 / place-01~e.9\\n'\n",
      " '                  :ARG1 z3\\n'\n",
      " '                  :ARG2 (z9 / refrigerator~e.11))\\n'\n",
      " '            :op2 (z10 / chill-01~e.13\\n'\n",
      " '                  :ARG1 z3)\\n'\n",
      " '            :time (z11 / then~e.8)\\n'\n",
      " '            :time (z12 / overnight~e.14)))')\n"
     ]
    }
   ],
   "source": [
    "print(sent)\n",
    "pprint(aligned_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0-z1 ': ('2', 0, 1, 2),\n",
      " '0-z10 ': ('light', 9, 14, 15),\n",
      " '0-z11 ': ('not', 14, 21, 22),\n",
      " '0-z2 ': ('Whisk', 2, 3, 6),\n",
      " '0-z4 ': ('yolks', 5, 8, 11),\n",
      " '0-z5 ': ('egg', 4, 7, 8),\n",
      " '0-z6 ': ('cook', 7, 12, 13),\n",
      " '0-z7 ': ('until', 8, 13, 14),\n",
      " '0-z8 ': ('forms', 11, 18, 19),\n",
      " '0-z9 ': ('custard', 10, 15, 18),\n",
      " '1-z1 ': ('3', 0, 1, 2),\n",
      " '1-z10 ': ('chill', 13, 14, 15),\n",
      " '1-z11 ': ('then', 8, 9, 10),\n",
      " '1-z12 ': ('overnight', 14, 15, 16),\n",
      " '1-z2 ': ('Remove', 2, 3, 4),\n",
      " '1-z4 ': ('and', 12, 13, 14),\n",
      " '1-z5 ': ('heat', 4, 5, 6),\n",
      " '1-z6 ': ('cool', 6, 7, 8),\n",
      " '1-z8 ': ('place', 9, 10, 11),\n",
      " '1-z9 ': ('refrigerator', 11, 12, 13)}\n"
     ]
    }
   ],
   "source": [
    "pprint(amr_dict[sent][\"node2str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "from intervals import *\n",
    "\n",
    "\n",
    "def dump_amrs(data_dir, splits, bert_model, text_tokenizer=\"scispacy\"):\n",
    "\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "    bad_counts = 0\n",
    "    import amrlib, spacy\n",
    "    from amrlib.graph_processing.annotator import add_lemmas\n",
    "    from amrlib.alignments.rbw_aligner import RBWAligner\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(bert_model)\n",
    "    model = AutoModel.from_pretrained(bert_model)\n",
    "\n",
    "    amrlib.setup_spacy_extension()\n",
    "\n",
    "    if text_tokenizer == \"scispacy\":\n",
    "        nlp = spacy.load(\"en_core_sci_md\")\n",
    "    elif text_tokenizer == \"spacy\":\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    bad_amr_sents = open(f\"{data_dir}/bad_amr_sents.log\", \"w\")\n",
    "    sent_amr_dict = {}\n",
    "    amr_sents = set()\n",
    "    for split in splits:\n",
    "        docs = json.load(open(f\"{data_dir}/{split}.json\"))\n",
    "        for count, doc in enumerate(docs):\n",
    "            print(f\"Done for {count}/{len(docs)}\", end=\"\\r\")\n",
    "            rel_map = {}\n",
    "            lbl_cnt = ddict(int)\n",
    "            interdict = ddict(list)\n",
    "            parses_arr = []\n",
    "\n",
    "            sents = [x for x in nlp(doc[\"text\"]).sents]\n",
    "\n",
    "            for rel in doc[\"rels\"]:\n",
    "                start_span = min(rel[\"arg1_start\"], rel[\"arg2_start\"])\n",
    "                end_span = max(rel[\"arg1_end\"], rel[\"arg2_end\"])\n",
    "                rel_map[(start_span, end_span)] = (\n",
    "                    rel[\"arg1_start\"],\n",
    "                    rel[\"arg1_end\"],\n",
    "                    rel[\"arg1_word\"],\n",
    "                    rel[\"arg1_label\"],\n",
    "                    rel[\"arg2_start\"],\n",
    "                    rel[\"arg2_end\"],\n",
    "                    rel[\"arg2_word\"],\n",
    "                    rel[\"arg2_label\"],\n",
    "                    rel[\"arg_label\"],\n",
    "                )\n",
    "\n",
    "            # sent_idxs = [0]+[max([tok.idx for tok in sent])+1 for sent in sents]\n",
    "            sent_idxs = [0] + [sent.end_char for sent in sents]\n",
    "            sent_ints = [\n",
    "                (sent_idxs[i], sent_idxs[i + 1]) for i in range(0, len(sent_idxs) - 1)\n",
    "            ]\n",
    "            rel_ints = sorted(rel_map)\n",
    "\n",
    "            for rel_start, rel_end in rel_ints:\n",
    "                for sent_cnt, sent in enumerate(sent_ints):\n",
    "                    sent_start, sent_end = sent_ints[sent_cnt]\n",
    "                    if rel_start > sent_end:\n",
    "                        continue\n",
    "                    if rel_end < sent_start:\n",
    "                        break\n",
    "                    interdict[(rel_start, rel_end)].append(\n",
    "                        (sents[sent_cnt], sent_ints[sent_cnt][0])\n",
    "                    )\n",
    "\n",
    "            for rel_int in interdict:\n",
    "                (\n",
    "                    arg1_start,\n",
    "                    arg1_end,\n",
    "                    arg1_word,\n",
    "                    arg1_label,\n",
    "                    arg2_start,\n",
    "                    arg2_end,\n",
    "                    arg2_word,\n",
    "                    arg2_label,\n",
    "                    arg_lbl,\n",
    "                ) = rel_map[rel_int]\n",
    "                arg1_ann_map, arg2_ann_map, bw_arg_ann_map = (\n",
    "                    IntervalMapping(),\n",
    "                    IntervalMapping(),\n",
    "                    IntervalMapping(),\n",
    "                )\n",
    "\n",
    "                arg1_ann_map[arg1_start:arg1_end] = (arg1_start, arg1_end, arg1_label)\n",
    "                arg2_ann_map[arg2_start:arg2_end] = (arg2_start, arg2_end, arg2_label)\n",
    "                bw_arg_ann_map[min(arg1_start, arg2_start) : max(arg2_end, arg1_end)]\n",
    "\n",
    "                sent_str, sent_start = \"\", None\n",
    "\n",
    "                for elem in interdict[rel_int]:\n",
    "                    sent, sent_start_pos = elem\n",
    "                    if sent_start is None:\n",
    "                        sent_start = sent_start_pos\n",
    "                    sent_str += str(sent)\n",
    "                    sent_toks = sent\n",
    "                    amr_sents.add(sent_str)\n",
    "\n",
    "    print(f\"Total number of sentences = {len(amr_sents)}\")\n",
    "    return amr_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences = 2544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences = 3293\n"
     ]
    }
   ],
   "source": [
    "scispacy_sents = dump_amrs(\n",
    "    \"../data/risec/\",\n",
    "    [\"train\", \"dev\", \"test\"],\n",
    "    bert_model=\"bert-base-uncased\",\n",
    "    text_tokenizer=\"scispacy\",\n",
    ")\n",
    "spacy_sents = dump_amrs(\n",
    "    \"../data/risec/\",\n",
    "    [\"train\", \"dev\", \"test\"],\n",
    "    bert_model=\"bert-base-uncased\",\n",
    "    text_tokenizer=\"spacy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_sents = scispacy_sents & spacy_sents\n",
    "import amrlib, spacy\n",
    "from amrlib.graph_processing.annotator import add_lemmas\n",
    "from amrlib.alignments.rbw_aligner import RBWAligner\n",
    "\n",
    "amrlib.setup_spacy_extension()\n",
    "nlp_med = spacy.load(\"en_core_sci_md\")\n",
    "nlp_web = spacy.load(\"en_core_web_sm\")\n",
    "good_spans = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ::snt 1) Preheat oven to 350 degrees F (175 degrees C).\n",
      "# ::tokens [\"1\", \")\", \"Preheat\", \"oven\", \"to\", \"350\", \"degrees\", \"F\", \"(\", \"175\", \"degrees\", \"C\", \")\", \".\"]\n",
      "# ::lemmas [\"1\", \")\", \"preheat\", \"oven\", \"to\", \"350\", \"degrees\", \"F\", \"(\", \"175\", \"degrees\", \"C\", \")\", \".\"]\n",
      "# ::alignments 0-1.1 2-1 3-1.2 5-1.3.1\n",
      "(z1 / preheat-00~e.2\n",
      "      :li 1~e.0\n",
      "      :ARG1 (z2 / oven~e.3)\n",
      "      :ARG2 (z3 / temperature-quantity\n",
      "            :quant 350~e.5\n",
      "            :scale (z4 / fahrenheit)))\n"
     ]
    }
   ],
   "source": [
    "sent_str = \"1) Preheat oven to 350 degrees F (175 degrees C).\"\n",
    "doc = nlp_med(sent_str)\n",
    "\n",
    "for span in doc.sents:\n",
    "    graph_string = span._.to_amr()\n",
    "    penman_graph = add_lemmas(graph_string[0], snt_key=\"snt\")\n",
    "    aligner = RBWAligner.from_penman_w_json(\n",
    "        penman_graph\n",
    "    )  # use this with an annotated penman graph object\n",
    "    aligned_string = aligner.get_graph_string()\n",
    "\n",
    "    print(aligned_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('z1', ':instance', 'preheat-00'),\n",
       " ('z1', ':li', '1'),\n",
       " ('z1', ':ARG1', 'z2'),\n",
       " ('z2', ':instance', 'oven'),\n",
       " ('z1', ':ARG2', 'z3'),\n",
       " ('z3', ':instance', 'temperature-quantity'),\n",
       " ('z3', ':quant', '350'),\n",
       " ('z3', ':scale', 'z4'),\n",
       " ('z4', ':instance', 'fahrenheit')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penman_graph.triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 563/1390 [09:29<13:56,  1.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_343/978543854.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdoc\u001b[0m                    \u001b[0;34m=\u001b[0m \u001b[0mnlp_med\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mgraph_string\u001b[0m                                            \u001b[0;34m=\u001b[0m \u001b[0mspan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_amr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mpenman_graph\u001b[0m                                            \u001b[0;34m=\u001b[0m \u001b[0madd_lemmas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnt_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'snt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0maligner\u001b[0m                                                         \u001b[0;34m=\u001b[0m \u001b[0mRBWAligner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_penman_w_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenman_graph\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# use this with an annotated penman graph object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amr/lib/python3.7/site-packages/amrlib/__init__.py\u001b[0m in \u001b[0;36mspacy_stog_span\u001b[0;34m(span)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstog_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mload_stog_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstog_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_spans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Hook in the system as a spacy extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amr/lib/python3.7/site-packages/amrlib/models/parse_spring/inference.py\u001b[0m in \u001b[0;36mparse_spans\u001b[0;34m(self, spans, add_metadata)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_spans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspans\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amr/lib/python3.7/site-packages/amrlib/models/parse_spring/inference.py\u001b[0m in \u001b[0;36mparse_sents\u001b[0;34m(self, sents, add_metadata, return_penman, disable_progress, pbar_desc)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# model.config.max_length=20 is the base model. Set this much higher for generating AMR graphs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;31m# re-encode the model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amr/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amr/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m             )\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amr/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2214\u001b[0m                 \u001b[0mnext_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m                 \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2216\u001b[0;31m                 \u001b[0meos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2217\u001b[0m             )\n\u001b[1;32m   2218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amr/lib/python3.7/site-packages/transformers/generation_beam_search.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                     \u001b[0;31m# add next predicted token since it is not eos_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m                     \u001b[0mnext_beam_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m                     \u001b[0mnext_beam_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                     \u001b[0mnext_beam_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_beam_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for sent in tqdm(list(common_sents)):\n",
    "    # sent           = sent.replace(')','ʅ').replace('(','ʃ')\n",
    "    sent = sent.replace(\"\\n\", \" \")\n",
    "    doc = nlp_med(sent)\n",
    "    for count, span in enumerate(doc.sents):\n",
    "        graph_string = span._.to_amr()\n",
    "        penman_graph = add_lemmas(graph_string[0], snt_key=\"snt\")\n",
    "        aligner = RBWAligner.from_penman_w_json(\n",
    "            penman_graph\n",
    "        )  # use this with an annotated penman graph object\n",
    "        aligned_string = aligner.get_graph_string()\n",
    "        alignments = (\n",
    "            aligned_string.split(\"::\")[4]\n",
    "            .split(\"\\n\")[0]\n",
    "            .replace(\"alignments\", \"\")\n",
    "            .strip()\n",
    "            .split()\n",
    "        )\n",
    "        tokens = ast.literal_eval(\n",
    "            aligned_string.split(\"::\")[2].split(\"\\n\")[0][len(\"tokens\") + 1 :]\n",
    "        )\n",
    "\n",
    "# print(len(bad_spans))\n",
    "# print(len(common_sents))\n",
    "# print(len(good_spans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=3 python3 rel_classification_info.py --mode train --src_dataset chemu --tgt_dataset chemu --node_vec 768 --alpha 1 --gpu 3 --dep 1 --batch_size 10 --node_vec 768 &\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=2 python3 rel_classification_info.py --mode train --src_dataset chemu --tgt_dataset chemu --node_vec 768 --alpha 1 --gpu 3 --dep 0 --batch_size 10 --node_vec 768 &\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 python3 rel_classification_info.py --mode train --src_dataset mscorpus --tgt_dataset mscorpus --node_vec 768 --alpha 1 --gpu 3 --dep 1 --batch_size 10 --node_vec 768 &\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=1 python3 rel_classification_info.py --mode train --src_dataset mscorpus --tgt_dataset mscorpus --node_vec 768 --alpha 1 --gpu 3 --dep 0 --batch_size 10 --node_vec 768 &\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=4 python3 rel_classification_info.py --mode eval --src_dataset risec --tgt_dataset risec --node_vec 768 --alpha 1 --gpu 3 --dep 1 --batch_size 10 --node_vec 768 &\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=5 python3 rel_classification_info.py --mode eval --src_dataset risec --tgt_dataset risec --node_vec 768 --alpha 1 --gpu 3 --dep 0 --batch_size 10 --node_vec 768 &\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-igraph\n",
      "  Using cached python_igraph-0.9.10-py3-none-any.whl (9.1 kB)\n",
      "Collecting igraph==0.9.10\n",
      "  Downloading igraph-0.9.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting texttable>=1.6.2\n",
      "  Using cached texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: texttable, igraph, python-igraph\n",
      "Successfully installed igraph-0.9.10 python-igraph-0.9.10 texttable-1.6.4\n"
     ]
    }
   ],
   "source": [
    "! pip install python-igraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3689/3689 [00:00<00:00, 6454.18it/s]\n",
      "100%|██████████| 2213/2213 [00:00<00:00, 7303.87it/s]\n",
      "100%|██████████| 1689/1689 [00:00<00:00, 7309.90it/s]\n",
      "100%|██████████| 11411/11411 [00:02<00:00, 5346.36it/s]\n",
      "100%|██████████| 3332/3332 [00:00<00:00, 5660.59it/s]\n",
      "100%|██████████| 2885/2885 [00:00<00:00, 5715.27it/s]\n",
      "100%|██████████| 12330/12330 [00:02<00:00, 5135.03it/s]\n",
      "100%|██████████| 3782/3782 [00:00<00:00, 5752.36it/s]\n",
      "100%|██████████| 2287/2287 [00:00<00:00, 5536.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "from igraph import *\n",
    "\n",
    "data_dir = \"../data/\"\n",
    "lex_lang = ddict(list)\n",
    "dep_lang = ddict(list)\n",
    "sent_lang = ddict(list)\n",
    "\n",
    "\n",
    "def get_dep(dep_data):\n",
    "    edges = dep_data.edge_index.cpu().detach().numpy()\n",
    "    n1_mask, n2_mask = (\n",
    "        dep_data.n1_mask.cpu().detach().numpy(),\n",
    "        dep_data.n2_mask.cpu().detach().numpy(),\n",
    "    )\n",
    "    src_nodes = np.where(n1_mask == 1)[0]\n",
    "    tgt_nodes = np.where(n2_mask == 1)[0]\n",
    "    graph = Graph(directed=False)\n",
    "    graph.add_vertices(list(range(len(n1_mask))))\n",
    "    graph.add_edges([(n1, n2) for n1, n2 in zip(edges[0], edges[1])])\n",
    "    try:\n",
    "        sp = min(\n",
    "            [min(path_len) for path_len in graph.shortest_paths(src_nodes, tgt_nodes)]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        if len(src_nodes) > 0 and len(tgt_nodes) > 0:\n",
    "            sp = 0\n",
    "        else:\n",
    "            raise AssertionError\n",
    "\n",
    "    return sp\n",
    "\n",
    "\n",
    "for dataset in [\"risec\", \"chemu\", \"mscorpus\"]:\n",
    "    src_file = f\"{data_dir}/{dataset}/data.dill\"\n",
    "    src_dataset = load_dill(src_file)\n",
    "\n",
    "    for split in [\"train\", \"test\", \"dev\"]:\n",
    "        data = src_dataset[split][\"rels\"]\n",
    "        for idx in tqdm(range(0, len(data))):\n",
    "            arg1_start, arg2_start = data[idx][\"arg1_ids\"].index(1), data[idx][\n",
    "                \"arg2_ids\"\n",
    "            ].index(1)\n",
    "            arg1_end, arg2_end = (\n",
    "                arg1_start + np.sum(data[idx][\"arg1_ids\"]) - 1,\n",
    "                arg2_start + np.sum(data[idx][\"arg2_ids\"]) - 1,\n",
    "            )\n",
    "            lex_dist = max(arg1_start, arg2_start) - min(arg1_end, arg2_end)\n",
    "            lex_lang[dataset].append(lex_dist)\n",
    "            sp = get_dep(data[idx][\"dep_data\"])\n",
    "            dep_lang[dataset].append(sp)\n",
    "            sent_lang[dataset].append(len(data[idx][\"tokens\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent tokens\n",
      "risec 32.70939270188381 28.0 17.638530566502116\n",
      "chemu 95.01055139550715 67.0 76.74612624826047\n",
      "mscorpus 72.25805750312517 61.0 44.951131283328365\n",
      "Lexical distance\n",
      "risec 5.71136872612304 4.0 5.449745363434207\n",
      "chemu 13.630530973451327 6.0 20.11730214797887\n",
      "mscorpus 7.6212294146421 3.0 12.20073992286967\n",
      "Dependency distance\n",
      "risec 1.7432485838492953 1.0 1.2074174376122024\n",
      "chemu 2.0372135239391875 2.0 1.3776306997605046\n",
      "mscorpus 1.8618403174085547 1.0 1.5268098532557821\n"
     ]
    }
   ],
   "source": [
    "print(\"Sent tokens\")\n",
    "for lang in sent_lang:\n",
    "    print(\n",
    "        lang,\n",
    "        np.mean(sent_lang[lang]),\n",
    "        np.median(sent_lang[lang]),\n",
    "        np.std(sent_lang[lang]),\n",
    "    )\n",
    "\n",
    "print(\"Lexical distance\")\n",
    "\n",
    "for lang in lex_lang:\n",
    "    print(\n",
    "        lang, np.mean(lex_lang[lang]), np.median(lex_lang[lang]), np.std(lex_lang[lang])\n",
    "    )\n",
    "\n",
    "print(\"Dependency distance\")\n",
    "for lang in dep_lang:\n",
    "    print(\n",
    "        lang, np.mean(dep_lang[lang]), np.median(dep_lang[lang]), np.std(dep_lang[lang])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ff79ce7ab5a82e056583b400e21bd22a90a6e13ced07ba22e893052421dc6ac"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 ('med_ent')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
