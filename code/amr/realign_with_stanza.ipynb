{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import dill\n",
    "import penman\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/projects/flow_graphs/data/risec/amr.pkl\", \"rb\") as f:\n",
    "    amr_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ba36f2131744658a11d208f3d7ea1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32093fb3ef2422c851229f6f9bbc97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.0/models/sentiment/sstplus.pt:   0%|    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6817b3826a94fbe862191618a55cdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.0/models/constituency/wsj.pt:   0%|     …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15c916f815847d5829fa952a9ee41cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.0/models/ner/ontonotes.pt:   0%|        …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21730a1768754297977cae2863d8de71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.0/models/forward_charlm/1billion.pt:   0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ac582267a14fd8a6d12e77709531f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.0/models/backward_charlm/1billion.pt:   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 14:14:34 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-06-16 14:14:34 INFO: Use device: gpu\n",
      "2022-06-16 14:14:34 INFO: Loading: tokenize\n",
      "2022-06-16 14:14:40 INFO: Loading: pos\n",
      "2022-06-16 14:14:41 INFO: Loading: lemma\n",
      "2022-06-16 14:14:41 INFO: Loading: depparse\n",
      "2022-06-16 14:14:41 INFO: Loading: sentiment\n",
      "2022-06-16 14:14:42 INFO: Loading: constituency\n",
      "2022-06-16 14:14:43 INFO: Loading: ner\n",
      "2022-06-16 14:14:44 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza_nlp = stanza.Pipeline(lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2) Whisk in egg yolks and cook until light custard forms; do not boil.\n",
      "(z1 / and~e.5\n",
      "    :li 2\n",
      "    :op1 (z2 / whisk-01\n",
      "             :mode imperative\n",
      "             :arg0 (z3 / you)\n",
      "             :arg1 (z4 / yolk~e.4\n",
      "                       :mod (z5 / egg~e.3)))\n",
      "    :op2 (z6 / cook-01~e.6\n",
      "             :mode imperative\n",
      "             :arg0 z3\n",
      "             :time~e.2 (z7 / until~e.7\n",
      "                           :op1 (z8 / form~e.10\n",
      "                                    :mod (z9 / custard~e.9\n",
      "                                             :arg1-of (z10 / light-06~e.8)))))\n",
      "    :op3 (z11 / boil-01~e.13\n",
      "              :polarity~e.12 -~e.12\n",
      "              :mode~e.11 imperative\n",
      "              :arg0 z3))\n"
     ]
    }
   ],
   "source": [
    "doc_idx = 0\n",
    "sent_idx = 1\n",
    "\n",
    "graph = amr_data[doc_idx][sent_idx][\"graph\"]\n",
    "text = amr_data[doc_idx][sent_idx][\"text\"]\n",
    "print(text)\n",
    "print(penman.encode(graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: what is unaligned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "unaligned_triples = []\n",
    "unaligned_instances = []\n",
    "\n",
    "node_pattern = re.compile(r\"z\\d+\")\n",
    "pbf_pattern = re.compile(r\"\\w+-(\\d){2}\")\n",
    "\n",
    "\n",
    "def should_be_unaligned(triple):\n",
    "    return bool(node_pattern.fullmatch(triple[0])) and bool(node_pattern.match(triple[2]))\n",
    "\n",
    "\n",
    "def is_propbank_frame(node_str):\n",
    "    return bool(pbf_pattern.fullmatch(node_str))\n",
    "\n",
    "\n",
    "for doc in amr_data:\n",
    "    for sentence in doc:\n",
    "        amr_graph = sentence[\"graph\"]\n",
    "        if amr_graph is None:\n",
    "            continue\n",
    "        alignments = penman.surface.alignments(amr_graph)\n",
    "        for triple in amr_graph.triples:\n",
    "            if triple not in alignments and not should_be_unaligned(triple):\n",
    "                unaligned_triples.append(triple)\n",
    "                if triple[1] == \":instance\":\n",
    "                    unaligned_instances.append(triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({':instance': 1905,\n",
       "         ':li': 801,\n",
       "         ':mode': 235,\n",
       "         ':quant': 66,\n",
       "         ':polarity': 14,\n",
       "         ':frequency': 4,\n",
       "         ':op1': 10,\n",
       "         ':op2': 3,\n",
       "         ':op3': 1,\n",
       "         ':op4': 1})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([triple[1] for triple in unaligned_triples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[triple for triple in unaligned_triples if triple[1] == \":mode\" if triple[2] != \"imperative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1905, 743)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unaligned_instances), len(\n",
    "    [instance for instance in unaligned_instances if is_propbank_frame(instance[2])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('amr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6704d32e6c0a7cb18c31e26ad2d6dc79eb49d8ba9199dbba6bc9f1d50c5263da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
