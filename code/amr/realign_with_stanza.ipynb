{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "import amrlib\n",
    "import dill\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import penman\n",
    "\n",
    "from annotate_datasets import align_tokens_to_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stanza_nlp = stanza.Pipeline(lang=\"en\")r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"risec\", \"japflow\", \"chemu\", \"mscorpus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: what is unaligned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unaligned_triples = {}\n",
    "unaligned_instances = {}\n",
    "\n",
    "# check unaligned words: if they occur enough, they're probably AMR-model fillins\n",
    "unaligned_words = []\n",
    "\n",
    "node_pattern = re.compile(r\"z\\d+\")\n",
    "pbf_pattern = re.compile(r\"(\\w+-)+(\\d){2}\")\n",
    "\n",
    "with open(\"/usr0/home/sgururaj/miniconda3/envs/amr/lib/python3.7/site-packages/amrlib/models/parse_spring/resources/additions.txt\") as f:\n",
    "    additions = f.read().split(\"\\n\")\n",
    "\n",
    "with open(\"code/amr/amr_keywords.txt\") as f:\n",
    "    amr_keywords = [word.strip() for word in f.readlines() if word.strip() and not word.startswith(\"#\")]\n",
    "\n",
    "def is_unit_instance(triple, graph):\n",
    "    s, r, t = triple\n",
    "    is_instance = r == \":instance\"\n",
    "    is_unit_instance = any([parent_triple[1] in {\":unit\", \":scale\"} and parent_triple[2] == s for parent_triple in graph.triples])\n",
    "    return is_instance and is_unit_instance\n",
    "\n",
    "def should_be_unaligned(triple, graph):\n",
    "    # if this is a node like z1 --> z2, or z1 --> temperature_quantity\n",
    "    is_node2node = bool(node_pattern.fullmatch(triple[0])) and bool(node_pattern.match(triple[2]))\n",
    "    # if this is an AMR specifier node\n",
    "    is_amr_keyword = triple[1] == \":instance\" and triple[2] in additions or triple[2] in amr_keywords\n",
    "    # if this is an intervening node triple\n",
    "    is_name_triple = bool(node_pattern.fullmatch(triple[0])) and triple[2] == \"name\"\n",
    "    # if this is a \"you\" truple\n",
    "    is_imperative = triple[2] == \"you\" or triple[1] == \":mode\" and triple[2] == \"imperative\"\n",
    "\n",
    "    return is_node2node or is_amr_keyword or is_name_triple or is_unit_instance(triple, graph) or is_imperative\n",
    "\n",
    "\n",
    "def is_propbank_frame(node_str):\n",
    "    return bool(pbf_pattern.fullmatch(node_str))\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    with open(f\"/scratch/sgururaj/flow_graphs/{dataset}/amr_train.pkl\", \"rb\") as f:\n",
    "        amr_data = pickle.load(f)\n",
    "    \n",
    "    unaligned_instances[dataset] = []\n",
    "    unaligned_triples[dataset] = []\n",
    "\n",
    "    for doc in amr_data:\n",
    "        for sentence in doc:\n",
    "            amr_graph = sentence[\"graph\"]\n",
    "            text = sentence[\"text\"]\n",
    "            if amr_graph is None or amr_graph.triples[0][0] is None:\n",
    "                continue\n",
    "            alignments = penman.surface.alignments(amr_graph)\n",
    "            for triple in amr_graph.triples:\n",
    "                if triple not in alignments and not should_be_unaligned(triple, amr_graph):\n",
    "                    unaligned_triples[dataset].append((triple, sentence))\n",
    "                    if triple[1] == \":instance\":\n",
    "                        unaligned_instances[dataset].append((triple, sentence))\n",
    "                        unaligned_words.append(triple[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 1555),\n",
       " ('mean-01', 781),\n",
       " ('between', 589),\n",
       " ('dry-02', 491),\n",
       " ('after', 386),\n",
       " ('add-02', 294),\n",
       " ('example', 232),\n",
       " ('equal-01', 225),\n",
       " ('slash', 175),\n",
       " ('heat-01', 169)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter = Counter(unaligned_words)\n",
    "word_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'risec': (defaultdict(<function __main__.<lambda>()>,\n",
       "              {'pbf': 765, 'hyphenated': 6}),\n",
       "  1139),\n",
       " 'japflow': (defaultdict(<function __main__.<lambda>()>,\n",
       "              {'pbf': 2280, 'hyphenated': 18}),\n",
       "  3629),\n",
       " 'chemu': (defaultdict(<function __main__.<lambda>()>,\n",
       "              {'pbf': 2302, 'hyphenated': 275}),\n",
       "  5601),\n",
       " 'mscorpus': (defaultdict(<function __main__.<lambda>()>,\n",
       "              {'pbf': 1068, 'hyphenated': 129}),\n",
       "  2462)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_counts = {}\n",
    "\n",
    "mystery = []\n",
    "hyphens = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    err_counts = defaultdict(lambda: 0) \n",
    "    unaligned = unaligned_instances[dataset]\n",
    "    for (s,r,t), _ in unaligned:\n",
    "        if t in additions or t in amr_keywords:\n",
    "            err_counts[\"keywords\"] += 1\n",
    "        elif pbf_pattern.match(t):\n",
    "            err_counts[\"pbf\"] += 1\n",
    "        elif \"-\" in t:\n",
    "            err_counts[\"hyphenated\"] += 1\n",
    "            hyphens.append(t)\n",
    "        elif t == \"you\":\n",
    "            err_counts[\"you\"] +=1\n",
    "        else:\n",
    "            mystery.append(t)\n",
    "    error_counts[dataset] = err_counts, len(unaligned)\n",
    "\n",
    "error_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaway here: some hyphenated words do exist: match against these by replacing hyphens and seeing if you can find a string match. Other hyphenated words are weird, and do not appear in the AMR spec, so not sure if they're valid to use or add there. The vast majority of unaligned words seem actually to be just that: unaligned words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 100), ('between', 57), ('juice', 25), ('cinnamon', 20), ('bubbly', 5), ('fryer', 4), ('cayenne', 4), ('chill', 4), ('parmesan', 4), ('sprinkle', 4), ('more', 4), ('we', 4), ('ratio-of', 3), ('oat', 3), ('aluminum', 3), ('worcestershire', 3), ('cilantro', 3), ('gradual', 3), ('layer', 3), ('cumin', 3)]\n",
      "[('and', 304), ('between', 151), ('gas', 130), ('juice', 81), ('or', 75), ('meanwhile', 27), ('slash', 26), ('ice', 24), ('lid', 21), ('cumin', 18), ('thyme', 18), ('cinnamon', 16), ('zest', 15), ('wok', 15), ('after', 13), ('more', 13), ('cheese', 12), ('then', 11), ('pan', 10), ('i', 10)]\n",
      "[('and', 944), ('between', 305), ('after', 277), ('example', 232), ('compound', 121), ('slash', 110), ('step', 105), ('ratio-of', 72), ('water', 62), ('or', 61), ('then', 59), ('this', 48), ('intermediate', 38), ('tetrahydrofuran', 36), ('hexane', 35), ('small-methanol', 32), ('method', 29), ('angle-quantity', 29), ('string-entity', 28), ('column', 25)]\n",
      "[('and', 207), ('after', 94), ('between', 76), ('all', 40), ('then', 38), ('slash', 37), ('ratio-of', 30), ('this', 28), ('final', 28), ('trinitrotoluene', 21), ('string-entity', 20), ('angle-quantity', 17), ('subsequent', 15), ('water', 13), ('ph', 13), ('powder', 12), ('method', 12), ('table', 10), ('grade', 9), ('hybrid', 9)]\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    unaligned = unaligned_instances[dataset]\n",
    "    print(Counter([t for (_, _, t), _ in unaligned if not pbf_pattern.match(t) and t not in additions and t not in amr_keywords]).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leaf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize(\"leaves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is worth to mention that POFA is a not toxic waste material in terms of heavy metals leachability [51].\n",
      "('z8', ':instance', 'possible-01')\n",
      "(z1 / worth-02~e.2\n",
      "    :arg2 (z2 / mention-01~e.4\n",
      "              :arg1 (z3 / material~e.12\n",
      "                        :polarity~e.9 -~e.9\n",
      "                        :mod (z4 / waste~e.11)\n",
      "                        :mod (z5 / toxic~e.10)\n",
      "                        :domain (z6 / small-molecule\n",
      "                                    :name (z7 / name\n",
      "                                              :op1 \"pofa\"))\n",
      "                        :topic (z8 / possible-01\n",
      "                                   :arg1 (z9 / leach-01~e.18\n",
      "                                             :arg1 (z10 / metal~e.17\n",
      "                                                        :mod (z11 / heavy~e.16))))\n",
      "                        :arg1-of (z12 / describe-01\n",
      "                                      :arg0 (z13 / publication\n",
      "                                                 :arg1-of (z14 / cite-01\n",
      "                                                               :arg2 51))))))\n"
     ]
    }
   ],
   "source": [
    "## visual inspection cell\n",
    "\n",
    "instance = random.choice(unaligned_instances[\"mscorpus\"])\n",
    "sentence = instance[1][\"text\"]\n",
    "graph = instance[1][\"graph\"]\n",
    "\n",
    "print(instance[1][\"text\"])\n",
    "print(instance[0])\n",
    "print(penman.encode(instance[1][\"graph\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('z1', ':instance', 'worth-02'): Alignment((2,), prefix='e.'),\n",
       " ('z2', ':instance', 'mention-01'): Alignment((4,), prefix='e.'),\n",
       " ('z3', ':instance', 'material'): Alignment((12,), prefix='e.'),\n",
       " ('z3', ':polarity', '-'): Alignment((9,), prefix='e.'),\n",
       " ('z4', ':instance', 'waste'): Alignment((11,), prefix='e.'),\n",
       " ('z5', ':instance', 'toxic'): Alignment((10,), prefix='e.'),\n",
       " ('z9', ':instance', 'leach-01'): Alignment((18,), prefix='e.'),\n",
       " ('z10', ':instance', 'metal'): Alignment((17,), prefix='e.'),\n",
       " ('z11', ':instance', 'heavy'): Alignment((16,), prefix='e.')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penman.surface.alignments(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unaligned_tokens(aligned_tokens, graph):\n",
    "    is_aligned = [False] * len(aligned_tokens)\n",
    "    for alignment in penman.surface.alignments(graph).values():\n",
    "        for index in alignment.indices:\n",
    "            is_aligned[index] = True\n",
    "    return [token for token_aligned, token in zip(is_aligned, aligned_tokens) if not token_aligned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_aligning_token(sentence, node, graph, lemmatizer):\n",
    "\n",
    "    default_pos = \"n\"\n",
    "    if pbf_pattern.match(node):\n",
    "        segments = node.split(\"-\")\n",
    "        if len(segments) > 2:\n",
    "            return None\n",
    "        else: \n",
    "            nodes = [segments[0]]\n",
    "            word_lemmas = [lemmatizer.lemmatize(node.replace('\"', \"\"), pos=\"v\") for node in nodes]\n",
    "            default_pos = \"v\"\n",
    "    elif \"-\" in node:\n",
    "        nodes = node.split(\"-\")\n",
    "        word_lemmas = [lemmatizer.lemmatize(node.strip('\"')) for node in nodes]\n",
    "    else:\n",
    "        nodes = [node]\n",
    "        word_lemmas = [lemmatizer.lemmatize(node.strip('\"')) for node in nodes]\n",
    "\n",
    "    char_aligned_tokens = align_tokens_to_sentence([token for token in re.split(\"\\s+\", sentence) if token.strip()], sentence)\n",
    "    unaligned_tokens = get_unaligned_tokens(char_aligned_tokens, graph)\n",
    "    newly_aligned_tokens = []\n",
    "\n",
    "    for word_lemma in word_lemmas:\n",
    "        for unaligned_token in unaligned_tokens:\n",
    "            unaligned_text = unaligned_token.token_str\n",
    "            \n",
    "            unaligned_lemma = lemmatizer.lemmatize(unaligned_text.lower().strip(string.punctuation), pos=default_pos)\n",
    "            if unaligned_lemma == word_lemma:\n",
    "                # print(word_lemma, unaligned_lemma)\n",
    "                newly_aligned_tokens.append(unaligned_token)\n",
    "    if not newly_aligned_tokens:\n",
    "        return None\n",
    "    else:\n",
    "        return newly_aligned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is worth to mention that POFA is a not toxic waste material in terms of heavy metals leachability [51].\n",
      "('z8', ':instance', 'possible-01')\n",
      "None\n",
      "\n",
      "(z1 / worth-02~e.2\n",
      "    :arg2 (z2 / mention-01~e.4\n",
      "              :arg1 (z3 / material~e.12\n",
      "                        :polarity~e.9 -~e.9\n",
      "                        :mod (z4 / waste~e.11)\n",
      "                        :mod (z5 / toxic~e.10)\n",
      "                        :domain (z6 / small-molecule\n",
      "                                    :name (z7 / name\n",
      "                                              :op1 \"pofa\"))\n",
      "                        :topic (z8 / possible-01\n",
      "                                   :arg1 (z9 / leach-01~e.18\n",
      "                                             :arg1 (z10 / metal~e.17\n",
      "                                                        :mod (z11 / heavy~e.16))))\n",
      "                        :arg1-of (z12 / describe-01\n",
      "                                      :arg0 (z13 / publication\n",
      "                                                 :arg1-of (z14 / cite-01\n",
      "                                                               :arg2 51))))))\n"
     ]
    }
   ],
   "source": [
    "sentence = instance[1][\"text\"]\n",
    "graph = instance[1][\"graph\"]\n",
    "\n",
    "print(instance[1][\"text\"])\n",
    "print(instance[0])\n",
    "print(search_for_aligning_token(sentence, instance[0][2], graph, wnl))\n",
    "print()\n",
    "\n",
    "print(penman.encode(instance[1][\"graph\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risec</th>\n",
       "      <th>japflow</th>\n",
       "      <th>chemu</th>\n",
       "      <th>mscorpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>triples</th>\n",
       "      <td>15750</td>\n",
       "      <td>54239</td>\n",
       "      <td>129382</td>\n",
       "      <td>47350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unaligned_fine</th>\n",
       "      <td>7826</td>\n",
       "      <td>31171</td>\n",
       "      <td>79960</td>\n",
       "      <td>28751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unaligned_concerning</th>\n",
       "      <td>2039</td>\n",
       "      <td>3936</td>\n",
       "      <td>17332</td>\n",
       "      <td>6131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concerning_fixed</th>\n",
       "      <td>1561</td>\n",
       "      <td>2599</td>\n",
       "      <td>8652</td>\n",
       "      <td>3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concerning_unfixed</th>\n",
       "      <td>478</td>\n",
       "      <td>1337</td>\n",
       "      <td>8680</td>\n",
       "      <td>3029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      risec  japflow   chemu  mscorpus\n",
       "triples               15750    54239  129382     47350\n",
       "unaligned_fine         7826    31171   79960     28751\n",
       "unaligned_concerning   2039     3936   17332      6131\n",
       "concerning_fixed       1561     2599    8652      3102\n",
       "concerning_unfixed      478     1337    8680      3029"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_counts = {}\n",
    "\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    with open(f\"/scratch/sgururaj/flow_graphs/{dataset}/amr_train.pkl\", \"rb\") as f:\n",
    "        amr_data = pickle.load(f)\n",
    "    alignment_counts[dataset] = defaultdict(lambda: 0)\n",
    "\n",
    "    for doc in amr_data:\n",
    "        for sentence in doc:\n",
    "            amr_graph = sentence[\"graph\"]\n",
    "            text = sentence[\"text\"]\n",
    "            if amr_graph is None or amr_graph.triples[0][0] is None:\n",
    "                continue\n",
    "            alignments = penman.surface.alignments(amr_graph)\n",
    "            for triple in amr_graph.triples:\n",
    "                alignment_counts[dataset][\"triples\"] += 1\n",
    "                if triple not in alignments and should_be_unaligned(triple, amr_graph):\n",
    "                    alignment_counts[dataset][\"unaligned_fine\"] += 1\n",
    "                if triple not in alignments and not should_be_unaligned(triple, amr_graph):\n",
    "                    alignment_counts[dataset][\"unaligned_concerning\"] += 1\n",
    "\n",
    "                    new_alignment = search_for_aligning_token(text, triple[2], amr_graph, wnl)\n",
    "                    if new_alignment is None:\n",
    "                        alignment_counts[dataset][\"concerning_unfixed\"] += 1\n",
    "                    else:\n",
    "                        alignment_counts[dataset][\"concerning_fixed\"] += 1\n",
    "\n",
    "pd.DataFrame(alignment_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('amr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6704d32e6c0a7cb18c31e26ad2d6dc79eb49d8ba9199dbba6bc9f1d50c5263da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
