{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import dill\n",
    "import json\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "import amrlib\n",
    "from amrlib import load_stog_model\n",
    "from amrlib.graph_processing.amr_plot import AMRPlot\n",
    "from amrlib.graph_processing.amr_loading import load_amr_entries\n",
    "from amrlib.graph_processing.annotator import add_lemmas\n",
    "from amrlib.alignments.rbw_aligner import RBWAligner\n",
    "from amrlib.alignments.faa_aligner import FAA_Aligner\n",
    "import penman\n",
    "from penman.surface import Alignment\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "amr_model = load_stog_model(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/projects/flow_graphs/data/risec/amr.pkl\", \"rb\" ) as f:\n",
    "    graphs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graphs[0][0][\"graph\"]\n",
    "tokens = graphs[0][0][\"tokens\"]\n",
    "text = graphs[0][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2 = amr_model.parse_sents([\"Pierre Vinken, 61, joined the board this year\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amr.png'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph2\n",
    "plot = AMRPlot(render_fn=\"./amr\", format=\"png\")\n",
    "\n",
    "plot.build_from_graph(graph2, debug=False)\n",
    "plot.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amr.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot = AMRPlot(render_fn=\"./amr\", format=\"png\")\n",
    "plot.build_from_graph(penman.encode(graph), debug=False)\n",
    "plot.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz(graph):\n",
    "    print(penman.encodee(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1) In a saucepan over low heat, stir together the half-and-half and sugar.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = amr_model.parse_sents([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7-1 2-1.1 11-1.3 10-1.3.1 12-1.3.2 8-1.4 3-1.5 6-1.5.1 5-1.5.1.1 ']\n"
     ]
    }
   ],
   "source": [
    "inference = FAA_Aligner()\n",
    "amr_surface_aligns, alignment_strings = inference.align_sents([text], [graph])\n",
    "print(alignment_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " ')',\n",
       " 'In',\n",
       " 'a',\n",
       " 'saucepan',\n",
       " 'over',\n",
       " 'low',\n",
       " 'heat',\n",
       " ',',\n",
       " 'stir',\n",
       " 'together',\n",
       " 'the',\n",
       " 'half',\n",
       " '-',\n",
       " 'and',\n",
       " '-',\n",
       " 'half',\n",
       " 'and',\n",
       " 'sugar',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(z1 / stir-01~e.7 :li 1~e.2 :arg0 (z2 / you) :arg1 (z3 / and~e.11 :op1 (z4 / half-and-half~e.10) :op2 (z5 / sugar~e.12)) :mod (z6 / together~e.8) :location (z7 / saucepan~e.3 :location-of (z8 / heat~e.6 :arg1-of (z9 / low-04~e.5))))']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amr_surface_aligns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('z1', ':instance', 'stir-01'): Alignment((7,), prefix='e.'),\n",
       " ('z1', ':li', '1'): Alignment((2,), prefix='e.'),\n",
       " ('z3', ':instance', 'and'): Alignment((11,), prefix='e.'),\n",
       " ('z4', ':instance', 'half-and-half'): Alignment((10,), prefix='e.'),\n",
       " ('z5', ':instance', 'sugar'): Alignment((12,), prefix='e.'),\n",
       " ('z6', ':instance', 'together'): Alignment((8,), prefix='e.'),\n",
       " ('z7', ':instance', 'saucepan'): Alignment((3,), prefix='e.'),\n",
       " ('z8', ':instance', 'heat'): Alignment((6,), prefix='e.'),\n",
       " ('z9', ':instance', 'low-04'): Alignment((5,), prefix='e.')}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penman.surface.alignments(penman.decode(amr_surface_aligns[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('z1', ':instance', 'stir-01'),\n",
       " ('z1', ':li', '1'),\n",
       " ('z1', ':ARG0', 'z2'),\n",
       " ('z2', ':instance', 'you'),\n",
       " ('z1', ':ARG1', 'z3'),\n",
       " ('z3', ':instance', 'and'),\n",
       " ('z3', ':op1', 'z4'),\n",
       " ('z4', ':instance', 'half-and-half'),\n",
       " ('z3', ':op2', 'z5'),\n",
       " ('z5', ':instance', 'sugar'),\n",
       " ('z1', ':mod', 'z6'),\n",
       " ('z6', ':instance', 'together'),\n",
       " ('z1', ':location', 'z7'),\n",
       " ('z7', ':instance', 'saucepan'),\n",
       " ('z7', ':location-of', 'z8'),\n",
       " ('z8', ':instance', 'heat'),\n",
       " ('z8', ':ARG1-of', 'z9'),\n",
       " ('z9', ':instance', 'low-04')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_graph.triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_to_type = defaultdict(lambda : 1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first, get a node to idx mapping\n",
    "node_to_idx = {}\n",
    "for (s, r, t) in aligned_graph.triples:\n",
    "    if s not in node_to_idx:\n",
    "        node_to_idx[s] = len(node_to_idx)\n",
    "    if t not in node_to_idx:\n",
    "        node_to_idx[t] = len(node_to_idx)\n",
    "\n",
    "idx_to_node = {v:k for k, v in node_to_idx.items()}\n",
    "\n",
    "# iterate through the triples in order to:\n",
    "## get a node-to-token mapping \n",
    "## construct the COO format edge representation\n",
    "## construct the edge information\n",
    "token_to_node = defaultdict(list)\n",
    "edges = []\n",
    "edge_types = []\n",
    "\n",
    "alignments = penman.surface.alignments(aligned_graph)\n",
    "for triple in aligned_graph.triples:\n",
    "    s,r,t = triple \n",
    "    if triple in alignments:\n",
    "        for token_idx in alignments[triple].indices:\n",
    "            token_to_node[token_idx].append(node_to_idx[s])\n",
    "            token_to_node[token_idx].append(node_to_idx[t])\n",
    "    edges.append((node_to_idx[s], node_to_idx[t]))\n",
    "    edge_types.append(edge_to_type[r])\n",
    "\n",
    "\n",
    "tokenized_input_ids = [101]\n",
    "node_to_token = defaultdict(list)\n",
    "for i, token in enumerate(tokens):\n",
    "    tokenized = tokenizer(token, add_special_tokens=False)[\"input_ids\"]\n",
    "    current_idx = len(tokenized_input_ids)\n",
    "    tokenized_input_ids.extend(tokenized)\n",
    "    if i in token_to_node:\n",
    "        node_indices= token_to_node[i]\n",
    "        for node_idx in node_indices:\n",
    "            node_to_token[node_idx].extend(range(current_idx, current_idx + len(tokenized)))\n",
    "tokenized_input_ids.append(102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '[CLS]')\n",
      "(1, '1')\n",
      "(2, ')')\n",
      "(3, 'in')\n",
      "(4, 'a')\n",
      "(5, 'sauce')\n",
      "(6, '##pan')\n",
      "(7, 'over')\n",
      "(8, 'low')\n",
      "(9, 'heat')\n",
      "(10, ',')\n",
      "(11, 'stir')\n",
      "(12, 'together')\n",
      "(13, 'the')\n",
      "(14, 'half')\n",
      "(15, '-')\n",
      "(16, 'and')\n",
      "(17, '-')\n",
      "(18, 'half')\n",
      "(19, 'and')\n",
      "(20, 'sugar')\n",
      "(21, '.')\n",
      "(22, '[SEP]')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([str((i, tokenizer.decode(token))) for (i, token) in enumerate(tokenized_input_ids)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z1': [1, 11],\n",
       " '1': [1],\n",
       " 'z7': [5, 6],\n",
       " 'saucepan': [5, 6],\n",
       " 'z9': [8],\n",
       " 'low-04': [8],\n",
       " 'z8': [9],\n",
       " 'heat': [9],\n",
       " 'stir-01': [11],\n",
       " 'z6': [12],\n",
       " 'together': [12],\n",
       " 'z4': [14],\n",
       " 'half-and-half': [14],\n",
       " 'z3': [16],\n",
       " 'and': [16],\n",
       " 'z5': [20],\n",
       " 'sugar': [20]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{idx_to_node[k]: v for k,v in node_to_token.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ::snt 1) In a saucepan over low heat, stir together the half-and-half and sugar.\n",
      "# ::tokens [\"1\", \")\", \"In\", \"a\", \"saucepan\", \"over\", \"low\", \"heat\", \",\", \"stir\", \"together\", \"the\", \"half\", \"-\", \"and\", \"-\", \"half\", \"and\", \"sugar\", \".\"]\n",
      "# ::lemmas [\"1\", \")\", \"in\", \"a\", \"saucepan\", \"over\", \"low\", \"heat\", \",\", \"stir\", \"together\", \"the\", \"half\", \"-\", \"and\", \"-\", \"half\", \"and\", \"sugar\", \".\"]\n",
      "# ::alignments 0-1.1 4-1.5 6-1.5.1.1 7-1.5.1 9-1 10-1.4 12-1.3.1 14-1.3 18-1.3.2\n",
      "(z1 / stir-01~e.9~e.9\n",
      "    :li 1~e.0~e.0\n",
      "    :ARG0 (z2 / you)\n",
      "    :ARG1 (z3 / and~e.14~e.14\n",
      "              :op1 (z4 / half-and-half~e.12~e.12)\n",
      "              :op2 (z5 / sugar~e.18~e.18))\n",
      "    :mod (z6 / together~e.10~e.10)\n",
      "    :location (z7 / saucepan~e.4~e.4\n",
      "                  :location-of (z8 / heat~e.7~e.7\n",
      "                                   :ARG1-of (z9 / low-04~e.6~e.6))))\n"
     ]
    }
   ],
   "source": [
    "viz(aligned_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (3, 4),\n",
       " (0, 5),\n",
       " (5, 6),\n",
       " (5, 7),\n",
       " (7, 8),\n",
       " (5, 9),\n",
       " (9, 10),\n",
       " (0, 11),\n",
       " (11, 12),\n",
       " (0, 13),\n",
       " (13, 14),\n",
       " (13, 15),\n",
       " (15, 16),\n",
       " (15, 17),\n",
       " (17, 18)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'z1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_graph.top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'triples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_920/1230052917.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maligned_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mnode_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'triples'"
     ]
    }
   ],
   "source": [
    "node_to_idx = {\"head_node\": 0}\n",
    "tokenized_input_ids = [101]\n",
    "edges = []\n",
    "edge_types = []\n",
    "node_to_token = defaultdict(list)\n",
    "\n",
    "\n",
    "\n",
    "for sentence in instance:\n",
    "    aligned_graph = sentence[\"graph\"]\n",
    "    tokens = sentence[\"tokens\"]\n",
    "\n",
    "    if aligned_graph is None:\n",
    "\n",
    "\n",
    "        for (s, r, t) in aligned_graph.triples:\n",
    "            if s not in node_to_idx:\n",
    "                node_to_idx[s] = len(node_to_idx)\n",
    "            if t not in node_to_idx:\n",
    "                node_to_idx[t] = len(node_to_idx)\n",
    "\n",
    "        token_to_node = defaultdict(list)\n",
    "\n",
    "\n",
    "        alignments = penman.surface.alignments(aligned_graph)\n",
    "        for triple in aligned_graph.triples:\n",
    "            s,r,t = triple \n",
    "            if triple in alignments:\n",
    "                for token_idx in alignments[triple].indices:\n",
    "                    token_to_node[token_idx].append(node_to_idx[s])\n",
    "                    token_to_node[token_idx].append(node_to_idx[t])\n",
    "            edges.append((node_to_idx[s], node_to_idx[t]))\n",
    "            edge_types.append(edge_to_type[r])\n",
    "        # add an edge linking to the top node across sentences\n",
    "        edges.append((0, node_to_idx[aligned_graph.top]))\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        tokenized = tokenizer(token, add_special_tokens=False)[\"input_ids\"]\n",
    "        current_idx = len(tokenized_input_ids)\n",
    "        tokenized_input_ids.extend(tokenized)\n",
    "        if i in token_to_node:\n",
    "            node_indices= token_to_node[i]\n",
    "            for node_idx in node_indices:\n",
    "                node_to_token[node_idx].extend(range(current_idx, current_idx + len(tokenized)))\n",
    "                \n",
    "tokenized_input_ids.append(102)\n",
    "idx_to_node = {v:k for k, v in node_to_idx.items()}\n",
    "node_to_token = dict(node_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6704d32e6c0a7cb18c31e26ad2d6dc79eb49d8ba9199dbba6bc9f1d50c5263da"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('amr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
